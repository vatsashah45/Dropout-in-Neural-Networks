{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a54b27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Dropout\n",
    "import json\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01272c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainM = np.loadtxt('x_trainM')\n",
    "y_trainM = np.loadtxt('y_trainM')\n",
    "x_testM = np.loadtxt('x_testM')\n",
    "y_testM = np.loadtxt('y_testM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f5a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = pd.read_csv('Results-MNIST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a40ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc58550a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(df2.iloc[16]['val_acc2'] - df2.iloc[0]['val_acc2'])/df2.iloc[0]['val_acc2'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2b443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25cc966",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse'],dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb3b6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,913,290\n",
      "Trainable params: 2,913,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 1.4991 - acc: 0.5475 - mae: 0.5240 - mse: 0.3274 - val_loss: 0.7003 - val_acc: 0.8055 - val_mae: 0.4710 - val_mse: 0.3366\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.5229 - acc: 0.8557 - mae: 0.4607 - mse: 0.3376 - val_loss: 0.4053 - val_acc: 0.8856 - val_mae: 0.4523 - val_mse: 0.3369\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3741 - acc: 0.8923 - mae: 0.4483 - mse: 0.3354 - val_loss: 0.3352 - val_acc: 0.9016 - val_mae: 0.4437 - val_mse: 0.3340\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3280 - acc: 0.9040 - mae: 0.4433 - mse: 0.3358 - val_loss: 0.3097 - val_acc: 0.9091 - val_mae: 0.4403 - val_mse: 0.3348\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3016 - acc: 0.9108 - mae: 0.4414 - mse: 0.3366 - val_loss: 0.2847 - val_acc: 0.9151 - val_mae: 0.4399 - val_mse: 0.3373\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2823 - acc: 0.9168 - mae: 0.4397 - mse: 0.3366 - val_loss: 0.2718 - val_acc: 0.9193 - val_mae: 0.4374 - val_mse: 0.3344\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2668 - acc: 0.9215 - mae: 0.4380 - mse: 0.3354 - val_loss: 0.2548 - val_acc: 0.9250 - val_mae: 0.4360 - val_mse: 0.3336\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2535 - acc: 0.9248 - mae: 0.4363 - mse: 0.3344 - val_loss: 0.2453 - val_acc: 0.9266 - val_mae: 0.4346 - val_mse: 0.3330\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2418 - acc: 0.9283 - mae: 0.4343 - mse: 0.3330 - val_loss: 0.2324 - val_acc: 0.9299 - val_mae: 0.4341 - val_mse: 0.3331\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2321 - acc: 0.9299 - mae: 0.4330 - mse: 0.3318 - val_loss: 0.2264 - val_acc: 0.9344 - val_mae: 0.4330 - val_mse: 0.3312\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2223 - acc: 0.9338 - mae: 0.4321 - mse: 0.3305 - val_loss: 0.2228 - val_acc: 0.9340 - val_mae: 0.4293 - val_mse: 0.3276\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2134 - acc: 0.9367 - mae: 0.4301 - mse: 0.3282 - val_loss: 0.2117 - val_acc: 0.9360 - val_mae: 0.4266 - val_mse: 0.3246\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2062 - acc: 0.9379 - mae: 0.4279 - mse: 0.3261 - val_loss: 0.2060 - val_acc: 0.9372 - val_mae: 0.4268 - val_mse: 0.3248\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1998 - acc: 0.9397 - mae: 0.4261 - mse: 0.3241 - val_loss: 0.1989 - val_acc: 0.9404 - val_mae: 0.4241 - val_mse: 0.3246\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1924 - acc: 0.9426 - mae: 0.4236 - mse: 0.3215 - val_loss: 0.1942 - val_acc: 0.9410 - val_mae: 0.4186 - val_mse: 0.3164\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1857 - acc: 0.9448 - mae: 0.4213 - mse: 0.3192 - val_loss: 0.1872 - val_acc: 0.9433 - val_mae: 0.4191 - val_mse: 0.3163\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1793 - acc: 0.9464 - mae: 0.4189 - mse: 0.3166 - val_loss: 0.1836 - val_acc: 0.9443 - val_mae: 0.4204 - val_mse: 0.3176\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1735 - acc: 0.9484 - mae: 0.4164 - mse: 0.3139 - val_loss: 0.1791 - val_acc: 0.9452 - val_mae: 0.4132 - val_mse: 0.3107\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1675 - acc: 0.9499 - mae: 0.4141 - mse: 0.3112 - val_loss: 0.1710 - val_acc: 0.9482 - val_mae: 0.4101 - val_mse: 0.3066\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1630 - acc: 0.9507 - mae: 0.4104 - mse: 0.3077 - val_loss: 0.1724 - val_acc: 0.9490 - val_mae: 0.4099 - val_mse: 0.3103\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1575 - acc: 0.9532 - mae: 0.4072 - mse: 0.3041 - val_loss: 0.1634 - val_acc: 0.9507 - val_mae: 0.4059 - val_mse: 0.3032\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1525 - acc: 0.9544 - mae: 0.4045 - mse: 0.3015 - val_loss: 0.1648 - val_acc: 0.9494 - val_mae: 0.4018 - val_mse: 0.2992\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1473 - acc: 0.9561 - mae: 0.4008 - mse: 0.2979 - val_loss: 0.1561 - val_acc: 0.9513 - val_mae: 0.4008 - val_mse: 0.2981\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1431 - acc: 0.9568 - mae: 0.3980 - mse: 0.2953 - val_loss: 0.1491 - val_acc: 0.9559 - val_mae: 0.3972 - val_mse: 0.2936\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1387 - acc: 0.9584 - mae: 0.3945 - mse: 0.2917 - val_loss: 0.1499 - val_acc: 0.9536 - val_mae: 0.3936 - val_mse: 0.2911\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1346 - acc: 0.9596 - mae: 0.3912 - mse: 0.2890 - val_loss: 0.1450 - val_acc: 0.9552 - val_mae: 0.3885 - val_mse: 0.2849\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1320 - acc: 0.9604 - mae: 0.3872 - mse: 0.2850 - val_loss: 0.1467 - val_acc: 0.9563 - val_mae: 0.3855 - val_mse: 0.2831\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1274 - acc: 0.9611 - mae: 0.3847 - mse: 0.2826 - val_loss: 0.1379 - val_acc: 0.9580 - val_mae: 0.3822 - val_mse: 0.2819\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1236 - acc: 0.9633 - mae: 0.3809 - mse: 0.2796 - val_loss: 0.1386 - val_acc: 0.9571 - val_mae: 0.3804 - val_mse: 0.2787\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1210 - acc: 0.9636 - mae: 0.3789 - mse: 0.2774 - val_loss: 0.1357 - val_acc: 0.9588 - val_mae: 0.3733 - val_mse: 0.2720\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1174 - acc: 0.9647 - mae: 0.3750 - mse: 0.2742 - val_loss: 0.1322 - val_acc: 0.9599 - val_mae: 0.3730 - val_mse: 0.2716\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1140 - acc: 0.9664 - mae: 0.3719 - mse: 0.2717 - val_loss: 0.1283 - val_acc: 0.9607 - val_mae: 0.3700 - val_mse: 0.2692\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1107 - acc: 0.9671 - mae: 0.3695 - mse: 0.2695 - val_loss: 0.1286 - val_acc: 0.9597 - val_mae: 0.3687 - val_mse: 0.2685\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1080 - acc: 0.9675 - mae: 0.3657 - mse: 0.2662 - val_loss: 0.1249 - val_acc: 0.9610 - val_mae: 0.3627 - val_mse: 0.2633\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1049 - acc: 0.9687 - mae: 0.3626 - mse: 0.2639 - val_loss: 0.1258 - val_acc: 0.9609 - val_mae: 0.3590 - val_mse: 0.2579\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1017 - acc: 0.9697 - mae: 0.3595 - mse: 0.2612 - val_loss: 0.1227 - val_acc: 0.9624 - val_mae: 0.3584 - val_mse: 0.2636\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0989 - acc: 0.9699 - mae: 0.3565 - mse: 0.2588 - val_loss: 0.1220 - val_acc: 0.9623 - val_mae: 0.3593 - val_mse: 0.2632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0967 - acc: 0.9712 - mae: 0.3538 - mse: 0.2567 - val_loss: 0.1176 - val_acc: 0.9642 - val_mae: 0.3522 - val_mse: 0.2552\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0938 - acc: 0.9724 - mae: 0.3502 - mse: 0.2541 - val_loss: 0.1158 - val_acc: 0.9635 - val_mae: 0.3512 - val_mse: 0.2530\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0912 - acc: 0.9728 - mae: 0.3479 - mse: 0.2519 - val_loss: 0.1125 - val_acc: 0.9650 - val_mae: 0.3468 - val_mse: 0.2522\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0890 - acc: 0.9733 - mae: 0.3455 - mse: 0.2501 - val_loss: 0.1168 - val_acc: 0.9641 - val_mae: 0.3438 - val_mse: 0.2520\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0870 - acc: 0.9736 - mae: 0.3413 - mse: 0.2470 - val_loss: 0.1104 - val_acc: 0.9652 - val_mae: 0.3439 - val_mse: 0.2480\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0849 - acc: 0.9746 - mae: 0.3395 - mse: 0.2453 - val_loss: 0.1091 - val_acc: 0.9655 - val_mae: 0.3369 - val_mse: 0.2426\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0819 - acc: 0.9758 - mae: 0.3363 - mse: 0.2428 - val_loss: 0.1121 - val_acc: 0.9651 - val_mae: 0.3377 - val_mse: 0.2454\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0803 - acc: 0.9758 - mae: 0.3333 - mse: 0.2409 - val_loss: 0.1054 - val_acc: 0.9671 - val_mae: 0.3299 - val_mse: 0.2374\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0776 - acc: 0.9775 - mae: 0.3305 - mse: 0.2388 - val_loss: 0.1055 - val_acc: 0.9673 - val_mae: 0.3295 - val_mse: 0.2402\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0756 - acc: 0.9772 - mae: 0.3282 - mse: 0.2371 - val_loss: 0.1025 - val_acc: 0.9676 - val_mae: 0.3254 - val_mse: 0.2354\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0736 - acc: 0.9781 - mae: 0.3249 - mse: 0.2342 - val_loss: 0.1004 - val_acc: 0.9688 - val_mae: 0.3211 - val_mse: 0.2297\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0714 - acc: 0.9787 - mae: 0.3217 - mse: 0.2318 - val_loss: 0.1023 - val_acc: 0.9679 - val_mae: 0.3215 - val_mse: 0.2308\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0698 - acc: 0.9792 - mae: 0.3191 - mse: 0.2300 - val_loss: 0.0985 - val_acc: 0.9692 - val_mae: 0.3168 - val_mse: 0.2264\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0684 - acc: 0.9795 - mae: 0.3164 - mse: 0.2277 - val_loss: 0.0995 - val_acc: 0.9683 - val_mae: 0.3139 - val_mse: 0.2260\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0662 - acc: 0.9799 - mae: 0.3129 - mse: 0.2250 - val_loss: 0.0954 - val_acc: 0.9701 - val_mae: 0.3148 - val_mse: 0.2290\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0645 - acc: 0.9806 - mae: 0.3108 - mse: 0.2239 - val_loss: 0.0949 - val_acc: 0.9706 - val_mae: 0.3107 - val_mse: 0.2248\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0625 - acc: 0.9812 - mae: 0.3081 - mse: 0.2216 - val_loss: 0.0958 - val_acc: 0.9704 - val_mae: 0.3029 - val_mse: 0.2156\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0613 - acc: 0.9819 - mae: 0.3055 - mse: 0.2194 - val_loss: 0.0937 - val_acc: 0.9706 - val_mae: 0.3059 - val_mse: 0.2206\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0595 - acc: 0.9821 - mae: 0.3027 - mse: 0.2178 - val_loss: 0.0942 - val_acc: 0.9710 - val_mae: 0.3000 - val_mse: 0.2152\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0580 - acc: 0.9824 - mae: 0.2997 - mse: 0.2153 - val_loss: 0.0918 - val_acc: 0.9717 - val_mae: 0.2990 - val_mse: 0.2153\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0567 - acc: 0.9823 - mae: 0.2974 - mse: 0.2139 - val_loss: 0.0924 - val_acc: 0.9729 - val_mae: 0.2956 - val_mse: 0.2130\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0547 - acc: 0.9838 - mae: 0.2945 - mse: 0.2116 - val_loss: 0.0918 - val_acc: 0.9715 - val_mae: 0.2957 - val_mse: 0.2159\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0532 - acc: 0.9840 - mae: 0.2920 - mse: 0.2101 - val_loss: 0.0909 - val_acc: 0.9719 - val_mae: 0.2932 - val_mse: 0.2131\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0518 - acc: 0.9840 - mae: 0.2900 - mse: 0.2086 - val_loss: 0.0890 - val_acc: 0.9726 - val_mae: 0.2894 - val_mse: 0.2083\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0505 - acc: 0.9847 - mae: 0.2861 - mse: 0.2055 - val_loss: 0.0956 - val_acc: 0.9714 - val_mae: 0.2892 - val_mse: 0.2106\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0491 - acc: 0.9852 - mae: 0.2847 - mse: 0.2047 - val_loss: 0.0868 - val_acc: 0.9735 - val_mae: 0.2860 - val_mse: 0.2057\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0479 - acc: 0.9857 - mae: 0.2826 - mse: 0.2033 - val_loss: 0.0879 - val_acc: 0.9730 - val_mae: 0.2823 - val_mse: 0.2041\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0466 - acc: 0.9859 - mae: 0.2801 - mse: 0.2017 - val_loss: 0.0873 - val_acc: 0.9732 - val_mae: 0.2805 - val_mse: 0.2023\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0450 - acc: 0.9862 - mae: 0.2769 - mse: 0.1992 - val_loss: 0.0905 - val_acc: 0.9729 - val_mae: 0.2756 - val_mse: 0.1984\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0439 - acc: 0.9867 - mae: 0.2750 - mse: 0.1975 - val_loss: 0.0847 - val_acc: 0.9748 - val_mae: 0.2737 - val_mse: 0.1965\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0429 - acc: 0.9869 - mae: 0.2724 - mse: 0.1961 - val_loss: 0.0839 - val_acc: 0.9757 - val_mae: 0.2714 - val_mse: 0.1960\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0409 - acc: 0.9877 - mae: 0.2703 - mse: 0.1946 - val_loss: 0.0870 - val_acc: 0.9742 - val_mae: 0.2718 - val_mse: 0.1970\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0405 - acc: 0.9880 - mae: 0.2672 - mse: 0.1925 - val_loss: 0.0858 - val_acc: 0.9749 - val_mae: 0.2674 - val_mse: 0.1925\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0392 - acc: 0.9884 - mae: 0.2655 - mse: 0.1909 - val_loss: 0.0822 - val_acc: 0.9761 - val_mae: 0.2646 - val_mse: 0.1909\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0380 - acc: 0.9888 - mae: 0.2626 - mse: 0.1894 - val_loss: 0.0848 - val_acc: 0.9753 - val_mae: 0.2614 - val_mse: 0.1881\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0371 - acc: 0.9892 - mae: 0.2611 - mse: 0.1881 - val_loss: 0.0854 - val_acc: 0.9750 - val_mae: 0.2597 - val_mse: 0.1880\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0357 - acc: 0.9892 - mae: 0.2587 - mse: 0.1868 - val_loss: 0.0812 - val_acc: 0.9761 - val_mae: 0.2583 - val_mse: 0.1862\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0348 - acc: 0.9904 - mae: 0.2566 - mse: 0.1850 - val_loss: 0.0800 - val_acc: 0.9762 - val_mae: 0.2581 - val_mse: 0.1863\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0338 - acc: 0.9901 - mae: 0.2541 - mse: 0.1835 - val_loss: 0.0850 - val_acc: 0.9745 - val_mae: 0.2566 - val_mse: 0.1851\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0330 - acc: 0.9905 - mae: 0.2526 - mse: 0.1824 - val_loss: 0.0847 - val_acc: 0.9756 - val_mae: 0.2509 - val_mse: 0.1818\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0318 - acc: 0.9908 - mae: 0.2500 - mse: 0.1808 - val_loss: 0.0817 - val_acc: 0.9756 - val_mae: 0.2455 - val_mse: 0.1771\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0304 - acc: 0.9909 - mae: 0.2472 - mse: 0.1786 - val_loss: 0.0883 - val_acc: 0.9752 - val_mae: 0.2428 - val_mse: 0.1749\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0295 - acc: 0.9916 - mae: 0.2449 - mse: 0.1770 - val_loss: 0.0847 - val_acc: 0.9756 - val_mae: 0.2441 - val_mse: 0.1767\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0289 - acc: 0.9917 - mae: 0.2438 - mse: 0.1763 - val_loss: 0.0794 - val_acc: 0.9768 - val_mae: 0.2419 - val_mse: 0.1744\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0281 - acc: 0.9921 - mae: 0.2416 - mse: 0.1749 - val_loss: 0.0853 - val_acc: 0.9753 - val_mae: 0.2456 - val_mse: 0.1806\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0275 - acc: 0.9923 - mae: 0.2398 - mse: 0.1740 - val_loss: 0.0826 - val_acc: 0.9764 - val_mae: 0.2402 - val_mse: 0.1740\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0265 - acc: 0.9923 - mae: 0.2366 - mse: 0.1714 - val_loss: 0.0811 - val_acc: 0.9779 - val_mae: 0.2392 - val_mse: 0.1741\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0255 - acc: 0.9928 - mae: 0.2357 - mse: 0.1710 - val_loss: 0.0798 - val_acc: 0.9767 - val_mae: 0.2340 - val_mse: 0.1697\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0245 - acc: 0.9930 - mae: 0.2337 - mse: 0.1692 - val_loss: 0.0797 - val_acc: 0.9780 - val_mae: 0.2341 - val_mse: 0.1716\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0237 - acc: 0.9933 - mae: 0.2318 - mse: 0.1683 - val_loss: 0.0832 - val_acc: 0.9761 - val_mae: 0.2323 - val_mse: 0.1700\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0234 - acc: 0.9936 - mae: 0.2297 - mse: 0.1670 - val_loss: 0.0871 - val_acc: 0.9757 - val_mae: 0.2340 - val_mse: 0.1718\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0225 - acc: 0.9938 - mae: 0.2280 - mse: 0.1657 - val_loss: 0.0826 - val_acc: 0.9766 - val_mae: 0.2259 - val_mse: 0.1633\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0218 - acc: 0.9942 - mae: 0.2261 - mse: 0.1648 - val_loss: 0.0859 - val_acc: 0.9764 - val_mae: 0.2277 - val_mse: 0.1687\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0209 - acc: 0.9942 - mae: 0.2249 - mse: 0.1642 - val_loss: 0.0815 - val_acc: 0.9773 - val_mae: 0.2278 - val_mse: 0.1677\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0205 - acc: 0.9945 - mae: 0.2231 - mse: 0.1629 - val_loss: 0.0821 - val_acc: 0.9767 - val_mae: 0.2245 - val_mse: 0.1639\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0199 - acc: 0.9945 - mae: 0.2221 - mse: 0.1625 - val_loss: 0.0800 - val_acc: 0.9769 - val_mae: 0.2207 - val_mse: 0.1606\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0192 - acc: 0.9950 - mae: 0.2195 - mse: 0.1605 - val_loss: 0.0805 - val_acc: 0.9776 - val_mae: 0.2197 - val_mse: 0.1596\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0184 - acc: 0.9952 - mae: 0.2178 - mse: 0.1593 - val_loss: 0.0860 - val_acc: 0.9764 - val_mae: 0.2184 - val_mse: 0.1604\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0180 - acc: 0.9953 - mae: 0.2167 - mse: 0.1587 - val_loss: 0.0807 - val_acc: 0.9777 - val_mae: 0.2151 - val_mse: 0.1567\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0174 - acc: 0.9955 - mae: 0.2147 - mse: 0.1572 - val_loss: 0.0822 - val_acc: 0.9773 - val_mae: 0.2156 - val_mse: 0.1582\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0163 - acc: 0.9959 - mae: 0.2130 - mse: 0.1564 - val_loss: 0.0826 - val_acc: 0.9774 - val_mae: 0.2134 - val_mse: 0.1572\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0162 - acc: 0.9959 - mae: 0.2112 - mse: 0.1551 - val_loss: 0.0851 - val_acc: 0.9772 - val_mae: 0.2153 - val_mse: 0.1594\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0159 - acc: 0.9960 - mae: 0.2098 - mse: 0.1542 - val_loss: 0.0823 - val_acc: 0.9779 - val_mae: 0.2121 - val_mse: 0.1570\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='sigmoid', input_shape = (784,)))\n",
    "model.add(Dense(1024, activation='sigmoid',))\n",
    "model.add(Dense(1024, activation='sigmoid',))\n",
    "\n",
    "model.add(Dense(10, activation='sigmoid',))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "score = model.fit(x_trainM, y_trainM, epochs=100, batch_size=80 ,validation_data=(x_testM, y_testM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cc62dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRow = [0.0]\n",
    "newRow.append(score.history['loss'][-1])\n",
    "newRow.append(score.history['acc'][-1])\n",
    "newRow.append(score.history['mae'][-1])\n",
    "newRow.append(score.history['mse'][-1])\n",
    "newRow.append(score.history['val_loss'][-1])\n",
    "newRow.append(score.history['val_acc'][-1])\n",
    "newRow.append(score.history['val_mae'][-1])\n",
    "newRow.append(score.history['val_mse'][-1])\n",
    "newDF = pd.DataFrame([newRow],columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ffc8ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,newDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b1ecf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17938"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(model)\n",
    "del(score)\n",
    "del(newRow)\n",
    "del(newDF)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa71e5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.209837</td>\n",
       "      <td>0.154195</td>\n",
       "      <td>0.082308</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.212091</td>\n",
       "      <td>0.156984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout      loss    acc       mae       mse  val_loss  val_acc   val_mae  \\\n",
       "0      0.0  0.015891  0.996  0.209837  0.154195  0.082308   0.9779  0.212091   \n",
       "\n",
       "    val_mse  \n",
       "0  0.156984  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ff21263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "                \n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(Dense(1024, activation='sigmoid', input_shape = (784,)))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(1024, activation='sigmoid',))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(1024, activation='sigmoid',))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(10, activation='sigmoid',))\n",
    "                \n",
    "                opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "                model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "                score = model.fit(x_trainM, y_trainM, epochs=100, batch_size=80 ,validation_data=(x_testM, y_testM),verbose=0)\n",
    "                \n",
    "                newRow = [i]\n",
    "                newRow.append(score.history['loss'][-1])\n",
    "                newRow.append(score.history['acc'][-1])\n",
    "                newRow.append(score.history['mae'][-1])\n",
    "                newRow.append(score.history['mse'][-1])\n",
    "                newRow.append(score.history['val_loss'][-1])\n",
    "                newRow.append(score.history['val_acc'][-1])\n",
    "                newRow.append(score.history['val_mae'][-1])\n",
    "                newRow.append(score.history['val_mse'][-1])\n",
    "                newDF = pd.DataFrame([newRow],columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse']) \n",
    "                df = pd.concat([df,newDF])\n",
    "                \n",
    "                del(model)\n",
    "                del(score)\n",
    "                del(newRow)\n",
    "                del(newDF)\n",
    "                gc.collect()\n",
    "                \n",
    "                print(count)\n",
    "                count += 1\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "998bd35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015891</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>0.209837</td>\n",
       "      <td>0.154195</td>\n",
       "      <td>0.082308</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.212091</td>\n",
       "      <td>0.156984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.030431</td>\n",
       "      <td>0.990100</td>\n",
       "      <td>0.211534</td>\n",
       "      <td>0.148709</td>\n",
       "      <td>0.070692</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.207372</td>\n",
       "      <td>0.144722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.039595</td>\n",
       "      <td>0.986933</td>\n",
       "      <td>0.225503</td>\n",
       "      <td>0.158620</td>\n",
       "      <td>0.070604</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.224746</td>\n",
       "      <td>0.156933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>0.983467</td>\n",
       "      <td>0.231120</td>\n",
       "      <td>0.160789</td>\n",
       "      <td>0.069482</td>\n",
       "      <td>0.9790</td>\n",
       "      <td>0.227323</td>\n",
       "      <td>0.155021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.061851</td>\n",
       "      <td>0.979967</td>\n",
       "      <td>0.234448</td>\n",
       "      <td>0.161312</td>\n",
       "      <td>0.074458</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.225029</td>\n",
       "      <td>0.150386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.078249</td>\n",
       "      <td>0.975633</td>\n",
       "      <td>0.233693</td>\n",
       "      <td>0.157164</td>\n",
       "      <td>0.081978</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.227134</td>\n",
       "      <td>0.149180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>0.968433</td>\n",
       "      <td>0.234998</td>\n",
       "      <td>0.154152</td>\n",
       "      <td>0.090553</td>\n",
       "      <td>0.9723</td>\n",
       "      <td>0.224762</td>\n",
       "      <td>0.141595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.135960</td>\n",
       "      <td>0.957817</td>\n",
       "      <td>0.258288</td>\n",
       "      <td>0.173242</td>\n",
       "      <td>0.107677</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.247616</td>\n",
       "      <td>0.159042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.199332</td>\n",
       "      <td>0.939167</td>\n",
       "      <td>0.301904</td>\n",
       "      <td>0.211091</td>\n",
       "      <td>0.144275</td>\n",
       "      <td>0.9553</td>\n",
       "      <td>0.291047</td>\n",
       "      <td>0.196173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.426529</td>\n",
       "      <td>0.879883</td>\n",
       "      <td>0.317306</td>\n",
       "      <td>0.217952</td>\n",
       "      <td>0.281371</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>0.300382</td>\n",
       "      <td>0.198138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout      loss       acc       mae       mse  val_loss  val_acc  \\\n",
       "0      0.0  0.015891  0.996000  0.209837  0.154195  0.082308   0.9779   \n",
       "0      0.1  0.030431  0.990100  0.211534  0.148709  0.070692   0.9779   \n",
       "0      0.2  0.039595  0.986933  0.225503  0.158620  0.070604   0.9783   \n",
       "0      0.3  0.050505  0.983467  0.231120  0.160789  0.069482   0.9790   \n",
       "0      0.4  0.061851  0.979967  0.234448  0.161312  0.074458   0.9765   \n",
       "0      0.5  0.078249  0.975633  0.233693  0.157164  0.081978   0.9745   \n",
       "0      0.6  0.101318  0.968433  0.234998  0.154152  0.090553   0.9723   \n",
       "0      0.7  0.135960  0.957817  0.258288  0.173242  0.107677   0.9681   \n",
       "0      0.8  0.199332  0.939167  0.301904  0.211091  0.144275   0.9553   \n",
       "0      0.9  0.426529  0.879883  0.317306  0.217952  0.281371   0.9205   \n",
       "\n",
       "    val_mae   val_mse  \n",
       "0  0.212091  0.156984  \n",
       "0  0.207372  0.144722  \n",
       "0  0.224746  0.156933  \n",
       "0  0.227323  0.155021  \n",
       "0  0.225029  0.150386  \n",
       "0  0.227134  0.149180  \n",
       "0  0.224762  0.141595  \n",
       "0  0.247616  0.159042  \n",
       "0  0.291047  0.196173  \n",
       "0  0.300382  0.198138  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fb1cf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results2-MNIST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fc2608",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01a9330c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse'],dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a23a9032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_40 (Dense)             (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 2,913,290\n",
      "Trainable params: 2,913,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 1.4883 - acc: 0.5499 - mae: 0.4751 - mse: 0.2736 - val_loss: 0.6988 - val_acc: 0.8123 - val_mae: 0.4432 - val_mse: 0.3097\n",
      "Epoch 2/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.5134 - acc: 0.8583 - mae: 0.4357 - mse: 0.3115 - val_loss: 0.4014 - val_acc: 0.8858 - val_mae: 0.4271 - val_mse: 0.3090\n",
      "Epoch 3/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3717 - acc: 0.8917 - mae: 0.4254 - mse: 0.3120 - val_loss: 0.3379 - val_acc: 0.9019 - val_mae: 0.4228 - val_mse: 0.3143\n",
      "Epoch 4/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3268 - acc: 0.9048 - mae: 0.4219 - mse: 0.3136 - val_loss: 0.3029 - val_acc: 0.9108 - val_mae: 0.4204 - val_mse: 0.3133\n",
      "Epoch 5/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3004 - acc: 0.9119 - mae: 0.4218 - mse: 0.3161 - val_loss: 0.2826 - val_acc: 0.9156 - val_mae: 0.4206 - val_mse: 0.3163\n",
      "Epoch 6/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2817 - acc: 0.9170 - mae: 0.4206 - mse: 0.3164 - val_loss: 0.2698 - val_acc: 0.9182 - val_mae: 0.4166 - val_mse: 0.3134\n",
      "Epoch 7/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2672 - acc: 0.9211 - mae: 0.4194 - mse: 0.3161 - val_loss: 0.2627 - val_acc: 0.9226 - val_mae: 0.4198 - val_mse: 0.3171\n",
      "Epoch 8/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2542 - acc: 0.9248 - mae: 0.4184 - mse: 0.3160 - val_loss: 0.2472 - val_acc: 0.9270 - val_mae: 0.4160 - val_mse: 0.3123\n",
      "Epoch 9/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2429 - acc: 0.9276 - mae: 0.4165 - mse: 0.3142 - val_loss: 0.2358 - val_acc: 0.9309 - val_mae: 0.4170 - val_mse: 0.3161\n",
      "Epoch 10/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2331 - acc: 0.9309 - mae: 0.4157 - mse: 0.3137 - val_loss: 0.2293 - val_acc: 0.9323 - val_mae: 0.4163 - val_mse: 0.3158\n",
      "Epoch 11/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2238 - acc: 0.9335 - mae: 0.4139 - mse: 0.3117 - val_loss: 0.2198 - val_acc: 0.9347 - val_mae: 0.4138 - val_mse: 0.3125\n",
      "Epoch 12/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2154 - acc: 0.9354 - mae: 0.4129 - mse: 0.3107 - val_loss: 0.2124 - val_acc: 0.9358 - val_mae: 0.4104 - val_mse: 0.3067\n",
      "Epoch 13/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2082 - acc: 0.9372 - mae: 0.4114 - mse: 0.3088 - val_loss: 0.2039 - val_acc: 0.9385 - val_mae: 0.4087 - val_mse: 0.3081\n",
      "Epoch 14/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2001 - acc: 0.9407 - mae: 0.4090 - mse: 0.3067 - val_loss: 0.2006 - val_acc: 0.9396 - val_mae: 0.4069 - val_mse: 0.3040\n",
      "Epoch 15/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1934 - acc: 0.9417 - mae: 0.4069 - mse: 0.3041 - val_loss: 0.1958 - val_acc: 0.9408 - val_mae: 0.4072 - val_mse: 0.3038\n",
      "Epoch 16/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1868 - acc: 0.9448 - mae: 0.4057 - mse: 0.3030 - val_loss: 0.1878 - val_acc: 0.9442 - val_mae: 0.4033 - val_mse: 0.3018\n",
      "Epoch 17/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1805 - acc: 0.9458 - mae: 0.4033 - mse: 0.3003 - val_loss: 0.1824 - val_acc: 0.9452 - val_mae: 0.3993 - val_mse: 0.2964\n",
      "Epoch 18/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1739 - acc: 0.9479 - mae: 0.3997 - mse: 0.2969 - val_loss: 0.1768 - val_acc: 0.9461 - val_mae: 0.3991 - val_mse: 0.2959\n",
      "Epoch 19/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1689 - acc: 0.9492 - mae: 0.3976 - mse: 0.2945 - val_loss: 0.1717 - val_acc: 0.9474 - val_mae: 0.3967 - val_mse: 0.2935\n",
      "Epoch 20/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1630 - acc: 0.9513 - mae: 0.3949 - mse: 0.2917 - val_loss: 0.1652 - val_acc: 0.9509 - val_mae: 0.3926 - val_mse: 0.2895\n",
      "Epoch 21/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1582 - acc: 0.9525 - mae: 0.3929 - mse: 0.2895 - val_loss: 0.1674 - val_acc: 0.9487 - val_mae: 0.3881 - val_mse: 0.2839\n",
      "Epoch 22/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1530 - acc: 0.9538 - mae: 0.3884 - mse: 0.2855 - val_loss: 0.1625 - val_acc: 0.9519 - val_mae: 0.3874 - val_mse: 0.2837\n",
      "Epoch 23/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1481 - acc: 0.9555 - mae: 0.3870 - mse: 0.2838 - val_loss: 0.1552 - val_acc: 0.9524 - val_mae: 0.3843 - val_mse: 0.2805\n",
      "Epoch 24/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1431 - acc: 0.9568 - mae: 0.3837 - mse: 0.2808 - val_loss: 0.1484 - val_acc: 0.9544 - val_mae: 0.3788 - val_mse: 0.2763\n",
      "Epoch 25/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1394 - acc: 0.9585 - mae: 0.3799 - mse: 0.2773 - val_loss: 0.1529 - val_acc: 0.9539 - val_mae: 0.3786 - val_mse: 0.2746\n",
      "Epoch 26/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1349 - acc: 0.9600 - mae: 0.3773 - mse: 0.2745 - val_loss: 0.1444 - val_acc: 0.9571 - val_mae: 0.3758 - val_mse: 0.2723\n",
      "Epoch 27/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1311 - acc: 0.9605 - mae: 0.3747 - mse: 0.2725 - val_loss: 0.1470 - val_acc: 0.9554 - val_mae: 0.3716 - val_mse: 0.2676\n",
      "Epoch 28/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1269 - acc: 0.9621 - mae: 0.3710 - mse: 0.2689 - val_loss: 0.1392 - val_acc: 0.9573 - val_mae: 0.3687 - val_mse: 0.2673\n",
      "Epoch 29/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1233 - acc: 0.9627 - mae: 0.3677 - mse: 0.2662 - val_loss: 0.1367 - val_acc: 0.9600 - val_mae: 0.3647 - val_mse: 0.2661\n",
      "Epoch 30/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1201 - acc: 0.9638 - mae: 0.3641 - mse: 0.2633 - val_loss: 0.1323 - val_acc: 0.9590 - val_mae: 0.3625 - val_mse: 0.2622\n",
      "Epoch 31/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1169 - acc: 0.9650 - mae: 0.3618 - mse: 0.2609 - val_loss: 0.1330 - val_acc: 0.9579 - val_mae: 0.3586 - val_mse: 0.2603\n",
      "Epoch 32/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1138 - acc: 0.9661 - mae: 0.3580 - mse: 0.2578 - val_loss: 0.1277 - val_acc: 0.9620 - val_mae: 0.3557 - val_mse: 0.2571\n",
      "Epoch 33/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1102 - acc: 0.9670 - mae: 0.3551 - mse: 0.2555 - val_loss: 0.1255 - val_acc: 0.9614 - val_mae: 0.3532 - val_mse: 0.2549\n",
      "Epoch 34/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1074 - acc: 0.9678 - mae: 0.3523 - mse: 0.2536 - val_loss: 0.1260 - val_acc: 0.9616 - val_mae: 0.3513 - val_mse: 0.2536\n",
      "Epoch 35/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1044 - acc: 0.9688 - mae: 0.3489 - mse: 0.2504 - val_loss: 0.1212 - val_acc: 0.9627 - val_mae: 0.3466 - val_mse: 0.2502\n",
      "Epoch 36/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1008 - acc: 0.9698 - mae: 0.3464 - mse: 0.2483 - val_loss: 0.1216 - val_acc: 0.9632 - val_mae: 0.3406 - val_mse: 0.2457\n",
      "Epoch 37/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0983 - acc: 0.9707 - mae: 0.3425 - mse: 0.2454 - val_loss: 0.1188 - val_acc: 0.9633 - val_mae: 0.3403 - val_mse: 0.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0958 - acc: 0.9706 - mae: 0.3387 - mse: 0.2424 - val_loss: 0.1141 - val_acc: 0.9642 - val_mae: 0.3370 - val_mse: 0.2421\n",
      "Epoch 39/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0934 - acc: 0.9718 - mae: 0.3355 - mse: 0.2399 - val_loss: 0.1140 - val_acc: 0.9645 - val_mae: 0.3374 - val_mse: 0.2431\n",
      "Epoch 40/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0907 - acc: 0.9730 - mae: 0.3337 - mse: 0.2386 - val_loss: 0.1141 - val_acc: 0.9650 - val_mae: 0.3278 - val_mse: 0.2332\n",
      "Epoch 41/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0878 - acc: 0.9741 - mae: 0.3302 - mse: 0.2358 - val_loss: 0.1166 - val_acc: 0.9638 - val_mae: 0.3311 - val_mse: 0.2362\n",
      "Epoch 42/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0860 - acc: 0.9746 - mae: 0.3268 - mse: 0.2329 - val_loss: 0.1089 - val_acc: 0.9664 - val_mae: 0.3237 - val_mse: 0.2296\n",
      "Epoch 43/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0836 - acc: 0.9751 - mae: 0.3232 - mse: 0.2304 - val_loss: 0.1113 - val_acc: 0.9648 - val_mae: 0.3233 - val_mse: 0.2301\n",
      "Epoch 44/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0817 - acc: 0.9752 - mae: 0.3205 - mse: 0.2281 - val_loss: 0.1036 - val_acc: 0.9690 - val_mae: 0.3174 - val_mse: 0.2254\n",
      "Epoch 45/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0789 - acc: 0.9765 - mae: 0.3179 - mse: 0.2263 - val_loss: 0.1023 - val_acc: 0.9680 - val_mae: 0.3158 - val_mse: 0.2267\n",
      "Epoch 46/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0763 - acc: 0.9770 - mae: 0.3152 - mse: 0.2241 - val_loss: 0.1006 - val_acc: 0.9675 - val_mae: 0.3123 - val_mse: 0.2237\n",
      "Epoch 47/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0745 - acc: 0.9770 - mae: 0.3110 - mse: 0.2209 - val_loss: 0.1037 - val_acc: 0.9677 - val_mae: 0.3106 - val_mse: 0.2210\n",
      "Epoch 48/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0724 - acc: 0.9786 - mae: 0.3087 - mse: 0.2194 - val_loss: 0.1069 - val_acc: 0.9665 - val_mae: 0.3062 - val_mse: 0.2185\n",
      "Epoch 49/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0706 - acc: 0.9783 - mae: 0.3052 - mse: 0.2166 - val_loss: 0.1013 - val_acc: 0.9681 - val_mae: 0.3031 - val_mse: 0.2148\n",
      "Epoch 50/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0686 - acc: 0.9792 - mae: 0.3027 - mse: 0.2148 - val_loss: 0.0954 - val_acc: 0.9700 - val_mae: 0.2987 - val_mse: 0.2118\n",
      "Epoch 51/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.0671 - acc: 0.9798 - mae: 0.2988 - mse: 0.2116 - val_loss: 0.0960 - val_acc: 0.9693 - val_mae: 0.2958 - val_mse: 0.2102\n",
      "Epoch 52/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0650 - acc: 0.9801 - mae: 0.2959 - mse: 0.2096 - val_loss: 0.0936 - val_acc: 0.9710 - val_mae: 0.2977 - val_mse: 0.2128\n",
      "Epoch 53/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0633 - acc: 0.9809 - mae: 0.2933 - mse: 0.2078 - val_loss: 0.0973 - val_acc: 0.9700 - val_mae: 0.2925 - val_mse: 0.2082\n",
      "Epoch 54/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0622 - acc: 0.9808 - mae: 0.2907 - mse: 0.2060 - val_loss: 0.0959 - val_acc: 0.9704 - val_mae: 0.2943 - val_mse: 0.2100\n",
      "Epoch 55/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0599 - acc: 0.9818 - mae: 0.2888 - mse: 0.2046 - val_loss: 0.0952 - val_acc: 0.9710 - val_mae: 0.2852 - val_mse: 0.2018\n",
      "Epoch 56/100\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 0.0581 - acc: 0.9823 - mae: 0.2850 - mse: 0.2017 - val_loss: 0.0896 - val_acc: 0.9723 - val_mae: 0.2825 - val_mse: 0.1990\n",
      "Epoch 57/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0570 - acc: 0.9828 - mae: 0.2821 - mse: 0.1997 - val_loss: 0.0899 - val_acc: 0.9734 - val_mae: 0.2801 - val_mse: 0.1971\n",
      "Epoch 58/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0547 - acc: 0.9831 - mae: 0.2797 - mse: 0.1978 - val_loss: 0.0894 - val_acc: 0.9734 - val_mae: 0.2809 - val_mse: 0.1999\n",
      "Epoch 59/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0538 - acc: 0.9837 - mae: 0.2777 - mse: 0.1965 - val_loss: 0.0927 - val_acc: 0.9723 - val_mae: 0.2760 - val_mse: 0.1971\n",
      "Epoch 60/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0520 - acc: 0.9841 - mae: 0.2737 - mse: 0.1934 - val_loss: 0.0894 - val_acc: 0.9727 - val_mae: 0.2716 - val_mse: 0.1930\n",
      "Epoch 61/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0507 - acc: 0.9847 - mae: 0.2717 - mse: 0.1923 - val_loss: 0.0894 - val_acc: 0.9725 - val_mae: 0.2703 - val_mse: 0.1908\n",
      "Epoch 62/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0492 - acc: 0.9853 - mae: 0.2694 - mse: 0.1903 - val_loss: 0.0899 - val_acc: 0.9731 - val_mae: 0.2658 - val_mse: 0.1882\n",
      "Epoch 63/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0480 - acc: 0.9855 - mae: 0.2669 - mse: 0.1889 - val_loss: 0.0884 - val_acc: 0.9736 - val_mae: 0.2632 - val_mse: 0.1851\n",
      "Epoch 64/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0466 - acc: 0.9859 - mae: 0.2636 - mse: 0.1865 - val_loss: 0.0853 - val_acc: 0.9736 - val_mae: 0.2647 - val_mse: 0.1886\n",
      "Epoch 65/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0454 - acc: 0.9861 - mae: 0.2617 - mse: 0.1854 - val_loss: 0.0840 - val_acc: 0.9751 - val_mae: 0.2604 - val_mse: 0.1839\n",
      "Epoch 66/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0443 - acc: 0.9864 - mae: 0.2595 - mse: 0.1834 - val_loss: 0.0854 - val_acc: 0.9748 - val_mae: 0.2578 - val_mse: 0.1812\n",
      "Epoch 67/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0427 - acc: 0.9871 - mae: 0.2567 - mse: 0.1814 - val_loss: 0.0863 - val_acc: 0.9744 - val_mae: 0.2600 - val_mse: 0.1852\n",
      "Epoch 68/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0414 - acc: 0.9874 - mae: 0.2546 - mse: 0.1800 - val_loss: 0.0894 - val_acc: 0.9733 - val_mae: 0.2578 - val_mse: 0.1855\n",
      "Epoch 69/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0402 - acc: 0.9882 - mae: 0.2523 - mse: 0.1786 - val_loss: 0.0853 - val_acc: 0.9750 - val_mae: 0.2538 - val_mse: 0.1801\n",
      "Epoch 70/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0393 - acc: 0.9882 - mae: 0.2498 - mse: 0.1769 - val_loss: 0.0848 - val_acc: 0.9757 - val_mae: 0.2498 - val_mse: 0.1775\n",
      "Epoch 71/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0379 - acc: 0.9885 - mae: 0.2476 - mse: 0.1754 - val_loss: 0.0838 - val_acc: 0.9748 - val_mae: 0.2482 - val_mse: 0.1748\n",
      "Epoch 72/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0369 - acc: 0.9896 - mae: 0.2451 - mse: 0.1735 - val_loss: 0.0829 - val_acc: 0.9762 - val_mae: 0.2434 - val_mse: 0.1713\n",
      "Epoch 73/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0359 - acc: 0.9899 - mae: 0.2436 - mse: 0.1725 - val_loss: 0.0822 - val_acc: 0.9764 - val_mae: 0.2432 - val_mse: 0.1735\n",
      "Epoch 74/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0349 - acc: 0.9896 - mae: 0.2412 - mse: 0.1710 - val_loss: 0.0843 - val_acc: 0.9761 - val_mae: 0.2457 - val_mse: 0.1753\n",
      "Epoch 75/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0340 - acc: 0.9903 - mae: 0.2392 - mse: 0.1696 - val_loss: 0.0814 - val_acc: 0.9764 - val_mae: 0.2375 - val_mse: 0.1681\n",
      "Epoch 76/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0326 - acc: 0.9905 - mae: 0.2372 - mse: 0.1683 - val_loss: 0.0841 - val_acc: 0.9756 - val_mae: 0.2372 - val_mse: 0.1694\n",
      "Epoch 77/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0318 - acc: 0.9907 - mae: 0.2348 - mse: 0.1666 - val_loss: 0.0801 - val_acc: 0.9766 - val_mae: 0.2334 - val_mse: 0.1659\n",
      "Epoch 78/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0307 - acc: 0.9912 - mae: 0.2335 - mse: 0.1660 - val_loss: 0.0791 - val_acc: 0.9768 - val_mae: 0.2350 - val_mse: 0.1675\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0296 - acc: 0.9912 - mae: 0.2319 - mse: 0.1648 - val_loss: 0.0819 - val_acc: 0.9768 - val_mae: 0.2288 - val_mse: 0.1622\n",
      "Epoch 80/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0292 - acc: 0.9916 - mae: 0.2296 - mse: 0.1633 - val_loss: 0.0850 - val_acc: 0.9751 - val_mae: 0.2299 - val_mse: 0.1647\n",
      "Epoch 81/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0283 - acc: 0.9918 - mae: 0.2276 - mse: 0.1623 - val_loss: 0.0802 - val_acc: 0.9771 - val_mae: 0.2315 - val_mse: 0.1662\n",
      "Epoch 82/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0274 - acc: 0.9920 - mae: 0.2257 - mse: 0.1609 - val_loss: 0.0857 - val_acc: 0.9757 - val_mae: 0.2231 - val_mse: 0.1577\n",
      "Epoch 83/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0262 - acc: 0.9926 - mae: 0.2233 - mse: 0.1590 - val_loss: 0.0822 - val_acc: 0.9768 - val_mae: 0.2242 - val_mse: 0.1606\n",
      "Epoch 84/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0258 - acc: 0.9926 - mae: 0.2222 - mse: 0.1587 - val_loss: 0.0797 - val_acc: 0.9768 - val_mae: 0.2226 - val_mse: 0.1608\n",
      "Epoch 85/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0246 - acc: 0.9930 - mae: 0.2203 - mse: 0.1575 - val_loss: 0.0811 - val_acc: 0.9771 - val_mae: 0.2204 - val_mse: 0.1579\n",
      "Epoch 86/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0242 - acc: 0.9931 - mae: 0.2187 - mse: 0.1564 - val_loss: 0.0831 - val_acc: 0.9771 - val_mae: 0.2212 - val_mse: 0.1598\n",
      "Epoch 87/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0239 - acc: 0.9933 - mae: 0.2163 - mse: 0.1546 - val_loss: 0.0841 - val_acc: 0.9760 - val_mae: 0.2196 - val_mse: 0.1585\n",
      "Epoch 88/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0221 - acc: 0.9940 - mae: 0.2153 - mse: 0.1541 - val_loss: 0.0824 - val_acc: 0.9770 - val_mae: 0.2175 - val_mse: 0.1563\n",
      "Epoch 89/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0218 - acc: 0.9940 - mae: 0.2140 - mse: 0.1533 - val_loss: 0.0806 - val_acc: 0.9779 - val_mae: 0.2126 - val_mse: 0.1528\n",
      "Epoch 90/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0210 - acc: 0.9943 - mae: 0.2114 - mse: 0.1515 - val_loss: 0.0795 - val_acc: 0.9783 - val_mae: 0.2115 - val_mse: 0.1529\n",
      "Epoch 91/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0207 - acc: 0.9943 - mae: 0.2099 - mse: 0.1505 - val_loss: 0.0804 - val_acc: 0.9771 - val_mae: 0.2101 - val_mse: 0.1513\n",
      "Epoch 92/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0201 - acc: 0.9945 - mae: 0.2084 - mse: 0.1498 - val_loss: 0.0845 - val_acc: 0.9769 - val_mae: 0.2116 - val_mse: 0.1541\n",
      "Epoch 93/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0191 - acc: 0.9952 - mae: 0.2070 - mse: 0.1490 - val_loss: 0.0844 - val_acc: 0.9763 - val_mae: 0.2041 - val_mse: 0.1465\n",
      "Epoch 94/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0182 - acc: 0.9954 - mae: 0.2050 - mse: 0.1475 - val_loss: 0.0824 - val_acc: 0.9765 - val_mae: 0.2070 - val_mse: 0.1497\n",
      "Epoch 95/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0174 - acc: 0.9955 - mae: 0.2035 - mse: 0.1468 - val_loss: 0.0808 - val_acc: 0.9779 - val_mae: 0.2064 - val_mse: 0.1494\n",
      "Epoch 96/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0168 - acc: 0.9957 - mae: 0.2022 - mse: 0.1455 - val_loss: 0.0841 - val_acc: 0.9775 - val_mae: 0.2006 - val_mse: 0.1457\n",
      "Epoch 97/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0163 - acc: 0.9958 - mae: 0.1998 - mse: 0.1440 - val_loss: 0.0830 - val_acc: 0.9781 - val_mae: 0.2026 - val_mse: 0.1467\n",
      "Epoch 98/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0157 - acc: 0.9963 - mae: 0.1992 - mse: 0.1440 - val_loss: 0.0834 - val_acc: 0.9778 - val_mae: 0.2008 - val_mse: 0.1460\n",
      "Epoch 99/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0157 - acc: 0.9960 - mae: 0.1979 - mse: 0.1432 - val_loss: 0.0843 - val_acc: 0.9776 - val_mae: 0.2005 - val_mse: 0.1461\n",
      "Epoch 100/100\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0145 - acc: 0.9965 - mae: 0.1967 - mse: 0.1423 - val_loss: 0.0839 - val_acc: 0.9776 - val_mae: 0.1969 - val_mse: 0.1432\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1024, activation='sigmoid', input_shape = (784,)))\n",
    "model.add(Dense(1024, activation='sigmoid',))\n",
    "model.add(Dense(1024, activation='sigmoid',))\n",
    "\n",
    "model.add(Dense(10, activation='sigmoid',))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "score = model.fit(x_trainM, y_trainM, epochs=100, batch_size=80 ,validation_data=(x_testM, y_testM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f7e825",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRow = [0.0]\n",
    "newRow.append(score.history['loss'][-1])\n",
    "newRow.append(score.history['acc'][-1])\n",
    "newRow.append(score.history['mae'][-1])\n",
    "newRow.append(score.history['mse'][-1])\n",
    "newRow.append(score.history['val_loss'][-1])\n",
    "newRow.append(score.history['val_acc'][-1])\n",
    "newRow.append(score.history['val_mae'][-1])\n",
    "newRow.append(score.history['val_mse'][-1])\n",
    "newDF = pd.DataFrame([newRow],columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b640dc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,newDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e21bdb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17779"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(model)\n",
    "del(score)\n",
    "del(newRow)\n",
    "del(newDF)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84baf86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.99645</td>\n",
       "      <td>0.196705</td>\n",
       "      <td>0.142339</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.196936</td>\n",
       "      <td>0.143228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout      loss      acc       mae       mse  val_loss  val_acc  \\\n",
       "0      0.0  0.014524  0.99645  0.196705  0.142339  0.083939   0.9776   \n",
       "\n",
       "    val_mae   val_mse  \n",
       "0  0.196936  0.143228  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aada8e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "FINISHED\n"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "                \n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(Dense(1024, activation='sigmoid', input_shape = (784,)))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(1024, activation='sigmoid',))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(1024, activation='sigmoid',))\n",
    "                \n",
    "                model.add(Dropout(i))\n",
    "                model.add(Dense(10, activation='sigmoid',))\n",
    "                \n",
    "                opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "                model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "                score = model.fit(x_trainM, y_trainM, epochs=100+int(100*i), batch_size=80 ,validation_data=(x_testM, y_testM),verbose=0)\n",
    "                \n",
    "                newRow = [i]\n",
    "                newRow.append(score.history['loss'][-1])\n",
    "                newRow.append(score.history['acc'][-1])\n",
    "                newRow.append(score.history['mae'][-1])\n",
    "                newRow.append(score.history['mse'][-1])\n",
    "                newRow.append(score.history['val_loss'][-1])\n",
    "                newRow.append(score.history['val_acc'][-1])\n",
    "                newRow.append(score.history['val_mae'][-1])\n",
    "                newRow.append(score.history['val_mse'][-1])\n",
    "                newDF = pd.DataFrame([newRow],columns=['dropout','loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse']) \n",
    "                df = pd.concat([df,newDF])\n",
    "                \n",
    "                del(model)\n",
    "                del(score)\n",
    "                del(newRow)\n",
    "                del(newDF)\n",
    "                gc.collect()\n",
    "                \n",
    "                print(count)\n",
    "                count += 1\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49380927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropout</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.996450</td>\n",
       "      <td>0.196705</td>\n",
       "      <td>0.142339</td>\n",
       "      <td>0.083939</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.196936</td>\n",
       "      <td>0.143228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.024964</td>\n",
       "      <td>0.991917</td>\n",
       "      <td>0.213846</td>\n",
       "      <td>0.154551</td>\n",
       "      <td>0.068545</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.211148</td>\n",
       "      <td>0.150970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.991033</td>\n",
       "      <td>0.210363</td>\n",
       "      <td>0.151259</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.206342</td>\n",
       "      <td>0.145911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.034913</td>\n",
       "      <td>0.988367</td>\n",
       "      <td>0.192545</td>\n",
       "      <td>0.132763</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.188090</td>\n",
       "      <td>0.126467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.040572</td>\n",
       "      <td>0.987100</td>\n",
       "      <td>0.207223</td>\n",
       "      <td>0.143412</td>\n",
       "      <td>0.065476</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>0.200862</td>\n",
       "      <td>0.136234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.052843</td>\n",
       "      <td>0.982783</td>\n",
       "      <td>0.202172</td>\n",
       "      <td>0.137305</td>\n",
       "      <td>0.065634</td>\n",
       "      <td>0.9800</td>\n",
       "      <td>0.195441</td>\n",
       "      <td>0.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.065721</td>\n",
       "      <td>0.978800</td>\n",
       "      <td>0.196124</td>\n",
       "      <td>0.129151</td>\n",
       "      <td>0.073496</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.184476</td>\n",
       "      <td>0.115638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.091933</td>\n",
       "      <td>0.970917</td>\n",
       "      <td>0.206533</td>\n",
       "      <td>0.134952</td>\n",
       "      <td>0.081828</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.192221</td>\n",
       "      <td>0.118599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.139521</td>\n",
       "      <td>0.957283</td>\n",
       "      <td>0.240022</td>\n",
       "      <td>0.159112</td>\n",
       "      <td>0.105176</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.222607</td>\n",
       "      <td>0.137648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.291401</td>\n",
       "      <td>0.918817</td>\n",
       "      <td>0.213579</td>\n",
       "      <td>0.128493</td>\n",
       "      <td>0.186335</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.180141</td>\n",
       "      <td>0.095897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dropout      loss       acc       mae       mse  val_loss  val_acc  \\\n",
       "0      0.0  0.014524  0.996450  0.196705  0.142339  0.083939   0.9776   \n",
       "0      0.1  0.024964  0.991917  0.213846  0.154551  0.068545   0.9791   \n",
       "0      0.2  0.028225  0.991033  0.210363  0.151259  0.065407   0.9803   \n",
       "0      0.3  0.034913  0.988367  0.192545  0.132763  0.065465   0.9811   \n",
       "0      0.4  0.040572  0.987100  0.207223  0.143412  0.065476   0.9809   \n",
       "0      0.5  0.052843  0.982783  0.202172  0.137305  0.065634   0.9800   \n",
       "0      0.6  0.065721  0.978800  0.196124  0.129151  0.073496   0.9779   \n",
       "0      0.7  0.091933  0.970917  0.206533  0.134952  0.081828   0.9754   \n",
       "0      0.8  0.139521  0.957283  0.240022  0.159112  0.105176   0.9679   \n",
       "0      0.9  0.291401  0.918817  0.213579  0.128493  0.186335   0.9455   \n",
       "\n",
       "    val_mae   val_mse  \n",
       "0  0.196936  0.143228  \n",
       "0  0.211148  0.150970  \n",
       "0  0.206342  0.145911  \n",
       "0  0.188090  0.126467  \n",
       "0  0.200862  0.136234  \n",
       "0  0.195441  0.128952  \n",
       "0  0.184476  0.115638  \n",
       "0  0.192221  0.118599  \n",
       "0  0.222607  0.137648  \n",
       "0  0.180141  0.095897  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23805649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results3-MNIST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f607b2b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
