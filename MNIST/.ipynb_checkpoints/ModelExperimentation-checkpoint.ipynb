{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acbff98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Dropout\n",
    "import json\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84531257",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainM = np.loadtxt('x_trainM')\n",
    "y_trainM = np.loadtxt('y_trainM')\n",
    "x_testM = np.loadtxt('x_testM')\n",
    "y_testM = np.loadtxt('y_testM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "072894e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['drop1','drop2','drop3']+\n",
    "                  ['loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse']+\n",
    "                  ['loss2', 'acc2', 'mae2', 'mse2', 'val_loss2', 'val_acc2', 'val_mae2', 'val_mse2'],dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "633261e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 419,110\n",
      "Trainable params: 419,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "750/750 [==============================] - 3s 3ms/step - loss: 2.0690 - acc: 0.4114 - mae: 0.5429 - mse: 0.3024 - val_loss: 1.5146 - val_acc: 0.6539 - val_mae: 0.5068 - val_mse: 0.2831\n",
      "Epoch 2/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 1.0854 - acc: 0.7221 - mae: 0.4708 - mse: 0.2833 - val_loss: 0.8004 - val_acc: 0.8086 - val_mae: 0.4464 - val_mse: 0.2849\n",
      "Epoch 3/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.6680 - acc: 0.8297 - mae: 0.4325 - mse: 0.2794 - val_loss: 0.5458 - val_acc: 0.8589 - val_mae: 0.4194 - val_mse: 0.2742\n",
      "Epoch 4/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.4934 - acc: 0.8688 - mae: 0.4088 - mse: 0.2673 - val_loss: 0.4319 - val_acc: 0.8824 - val_mae: 0.3991 - val_mse: 0.2623\n",
      "Epoch 5/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.4106 - acc: 0.8860 - mae: 0.3919 - mse: 0.2577 - val_loss: 0.3736 - val_acc: 0.8939 - val_mae: 0.3842 - val_mse: 0.2525\n",
      "Epoch 6/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3643 - acc: 0.8958 - mae: 0.3800 - mse: 0.2507 - val_loss: 0.3386 - val_acc: 0.9030 - val_mae: 0.3736 - val_mse: 0.2466\n",
      "Epoch 7/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3341 - acc: 0.9032 - mae: 0.3712 - mse: 0.2456 - val_loss: 0.3144 - val_acc: 0.9088 - val_mae: 0.3666 - val_mse: 0.2425\n",
      "Epoch 8/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.3126 - acc: 0.9085 - mae: 0.3644 - mse: 0.2412 - val_loss: 0.2986 - val_acc: 0.9127 - val_mae: 0.3607 - val_mse: 0.2381\n",
      "Epoch 9/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2958 - acc: 0.9138 - mae: 0.3586 - mse: 0.2374 - val_loss: 0.2827 - val_acc: 0.9152 - val_mae: 0.3546 - val_mse: 0.2343\n",
      "Epoch 10/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2818 - acc: 0.9173 - mae: 0.3540 - mse: 0.2343 - val_loss: 0.2689 - val_acc: 0.9189 - val_mae: 0.3512 - val_mse: 0.2321\n",
      "Epoch 11/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2695 - acc: 0.9206 - mae: 0.3498 - mse: 0.2312 - val_loss: 0.2614 - val_acc: 0.9209 - val_mae: 0.3479 - val_mse: 0.2301\n",
      "Epoch 12/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2583 - acc: 0.9233 - mae: 0.3463 - mse: 0.2283 - val_loss: 0.2504 - val_acc: 0.9245 - val_mae: 0.3435 - val_mse: 0.2263\n",
      "Epoch 13/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2484 - acc: 0.9263 - mae: 0.3426 - mse: 0.2256 - val_loss: 0.2413 - val_acc: 0.9265 - val_mae: 0.3392 - val_mse: 0.2223\n",
      "Epoch 14/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2392 - acc: 0.9291 - mae: 0.3394 - mse: 0.2226 - val_loss: 0.2333 - val_acc: 0.9293 - val_mae: 0.3355 - val_mse: 0.2195\n",
      "Epoch 15/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2304 - acc: 0.9315 - mae: 0.3358 - mse: 0.2197 - val_loss: 0.2260 - val_acc: 0.9315 - val_mae: 0.3327 - val_mse: 0.2169\n",
      "Epoch 16/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2221 - acc: 0.9340 - mae: 0.3325 - mse: 0.2167 - val_loss: 0.2190 - val_acc: 0.9335 - val_mae: 0.3305 - val_mse: 0.2150\n",
      "Epoch 17/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2144 - acc: 0.9358 - mae: 0.3295 - mse: 0.2140 - val_loss: 0.2120 - val_acc: 0.9352 - val_mae: 0.3287 - val_mse: 0.2139\n",
      "Epoch 18/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2071 - acc: 0.9385 - mae: 0.3263 - mse: 0.2112 - val_loss: 0.2082 - val_acc: 0.9378 - val_mae: 0.3247 - val_mse: 0.2100\n",
      "Epoch 19/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.2003 - acc: 0.9404 - mae: 0.3234 - mse: 0.2086 - val_loss: 0.2002 - val_acc: 0.9403 - val_mae: 0.3205 - val_mse: 0.2068\n",
      "Epoch 20/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1936 - acc: 0.9423 - mae: 0.3197 - mse: 0.2056 - val_loss: 0.1947 - val_acc: 0.9399 - val_mae: 0.3163 - val_mse: 0.2030\n",
      "Epoch 21/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1877 - acc: 0.9439 - mae: 0.3164 - mse: 0.2028 - val_loss: 0.1886 - val_acc: 0.9424 - val_mae: 0.3146 - val_mse: 0.2018\n",
      "Epoch 22/50\n",
      "750/750 [==============================] - 2s 2ms/step - loss: 0.1821 - acc: 0.9456 - mae: 0.3135 - mse: 0.2001 - val_loss: 0.1840 - val_acc: 0.9453 - val_mae: 0.3113 - val_mse: 0.1983\n",
      "Epoch 23/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1766 - acc: 0.9479 - mae: 0.3103 - mse: 0.1975 - val_loss: 0.1786 - val_acc: 0.9469 - val_mae: 0.3086 - val_mse: 0.1963\n",
      "Epoch 24/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1713 - acc: 0.9486 - mae: 0.3076 - mse: 0.1952 - val_loss: 0.1752 - val_acc: 0.9468 - val_mae: 0.3037 - val_mse: 0.1918\n",
      "Epoch 25/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1667 - acc: 0.9501 - mae: 0.3040 - mse: 0.1922 - val_loss: 0.1701 - val_acc: 0.9480 - val_mae: 0.3022 - val_mse: 0.1905\n",
      "Epoch 26/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1619 - acc: 0.9519 - mae: 0.3013 - mse: 0.1900 - val_loss: 0.1667 - val_acc: 0.9485 - val_mae: 0.2984 - val_mse: 0.1877\n",
      "Epoch 27/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1572 - acc: 0.9533 - mae: 0.2983 - mse: 0.1876 - val_loss: 0.1632 - val_acc: 0.9504 - val_mae: 0.2957 - val_mse: 0.1857\n",
      "Epoch 28/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1531 - acc: 0.9545 - mae: 0.2947 - mse: 0.1848 - val_loss: 0.1598 - val_acc: 0.9518 - val_mae: 0.2938 - val_mse: 0.1840\n",
      "Epoch 29/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1490 - acc: 0.9560 - mae: 0.2926 - mse: 0.1829 - val_loss: 0.1565 - val_acc: 0.9544 - val_mae: 0.2911 - val_mse: 0.1822\n",
      "Epoch 30/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1453 - acc: 0.9570 - mae: 0.2893 - mse: 0.1805 - val_loss: 0.1530 - val_acc: 0.9531 - val_mae: 0.2859 - val_mse: 0.1780\n",
      "Epoch 31/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1414 - acc: 0.9583 - mae: 0.2866 - mse: 0.1784 - val_loss: 0.1503 - val_acc: 0.9554 - val_mae: 0.2833 - val_mse: 0.1750\n",
      "Epoch 32/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1380 - acc: 0.9589 - mae: 0.2838 - mse: 0.1764 - val_loss: 0.1467 - val_acc: 0.9560 - val_mae: 0.2808 - val_mse: 0.1733\n",
      "Epoch 33/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1344 - acc: 0.9603 - mae: 0.2815 - mse: 0.1745 - val_loss: 0.1448 - val_acc: 0.9569 - val_mae: 0.2788 - val_mse: 0.1719\n",
      "Epoch 34/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1309 - acc: 0.9610 - mae: 0.2786 - mse: 0.1724 - val_loss: 0.1414 - val_acc: 0.9569 - val_mae: 0.2755 - val_mse: 0.1701\n",
      "Epoch 35/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1278 - acc: 0.9625 - mae: 0.2759 - mse: 0.1702 - val_loss: 0.1379 - val_acc: 0.9579 - val_mae: 0.2739 - val_mse: 0.1690\n",
      "Epoch 36/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1247 - acc: 0.9633 - mae: 0.2736 - mse: 0.1687 - val_loss: 0.1375 - val_acc: 0.9584 - val_mae: 0.2713 - val_mse: 0.1666\n",
      "Epoch 37/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1216 - acc: 0.9641 - mae: 0.2707 - mse: 0.1666 - val_loss: 0.1345 - val_acc: 0.9589 - val_mae: 0.2683 - val_mse: 0.1647\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1186 - acc: 0.9651 - mae: 0.2684 - mse: 0.1648 - val_loss: 0.1325 - val_acc: 0.9598 - val_mae: 0.2657 - val_mse: 0.1625\n",
      "Epoch 39/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1157 - acc: 0.9657 - mae: 0.2658 - mse: 0.1630 - val_loss: 0.1302 - val_acc: 0.9603 - val_mae: 0.2639 - val_mse: 0.1620\n",
      "Epoch 40/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1132 - acc: 0.9667 - mae: 0.2637 - mse: 0.1614 - val_loss: 0.1263 - val_acc: 0.9617 - val_mae: 0.2624 - val_mse: 0.1612\n",
      "Epoch 41/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1104 - acc: 0.9677 - mae: 0.2616 - mse: 0.1601 - val_loss: 0.1254 - val_acc: 0.9614 - val_mae: 0.2588 - val_mse: 0.1573\n",
      "Epoch 42/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1078 - acc: 0.9684 - mae: 0.2590 - mse: 0.1580 - val_loss: 0.1228 - val_acc: 0.9623 - val_mae: 0.2568 - val_mse: 0.1563\n",
      "Epoch 43/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1051 - acc: 0.9694 - mae: 0.2565 - mse: 0.1563 - val_loss: 0.1231 - val_acc: 0.9630 - val_mae: 0.2549 - val_mse: 0.1554\n",
      "Epoch 44/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1028 - acc: 0.9698 - mae: 0.2547 - mse: 0.1552 - val_loss: 0.1198 - val_acc: 0.9632 - val_mae: 0.2530 - val_mse: 0.1541\n",
      "Epoch 45/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.1005 - acc: 0.9709 - mae: 0.2524 - mse: 0.1535 - val_loss: 0.1191 - val_acc: 0.9632 - val_mae: 0.2505 - val_mse: 0.1522\n",
      "Epoch 46/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0982 - acc: 0.9717 - mae: 0.2504 - mse: 0.1522 - val_loss: 0.1169 - val_acc: 0.9647 - val_mae: 0.2489 - val_mse: 0.1521\n",
      "Epoch 47/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0959 - acc: 0.9725 - mae: 0.2478 - mse: 0.1503 - val_loss: 0.1167 - val_acc: 0.9652 - val_mae: 0.2466 - val_mse: 0.1494\n",
      "Epoch 48/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0938 - acc: 0.9735 - mae: 0.2459 - mse: 0.1491 - val_loss: 0.1134 - val_acc: 0.9655 - val_mae: 0.2436 - val_mse: 0.1473\n",
      "Epoch 49/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0916 - acc: 0.9735 - mae: 0.2440 - mse: 0.1478 - val_loss: 0.1116 - val_acc: 0.9654 - val_mae: 0.2432 - val_mse: 0.1479\n",
      "Epoch 50/50\n",
      "750/750 [==============================] - 2s 3ms/step - loss: 0.0897 - acc: 0.9740 - mae: 0.2419 - mse: 0.1462 - val_loss: 0.1100 - val_acc: 0.9663 - val_mae: 0.2399 - val_mse: 0.1454\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(300, activation='sigmoid', input_shape = (784,)))\n",
    "model.add(Dense(300, activation='sigmoid',))\n",
    "model.add(Dense(300, activation='sigmoid',))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='sigmoid',))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "score = model.fit(x_trainM, y_trainM, epochs=50, batch_size=80 ,validation_data=(x_testM, y_testM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "415aa0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRow = [0.0,0.0,0.0]\n",
    "newRow.append(score.history['loss'][-1])\n",
    "newRow.append(score.history['acc'][-1])\n",
    "newRow.append(score.history['mae'][-1])\n",
    "newRow.append(score.history['mse'][-1])\n",
    "newRow.append(score.history['val_loss'][-1])\n",
    "newRow.append(score.history['val_acc'][-1])\n",
    "newRow.append(score.history['val_mae'][-1])\n",
    "newRow.append(score.history['val_mse'][-1])\n",
    "newRow.append(score.history['loss'][-1])\n",
    "newRow.append(score.history['acc'][-1])\n",
    "newRow.append(score.history['mae'][-1])\n",
    "newRow.append(score.history['mse'][-1])\n",
    "newRow.append(score.history['val_loss'][-1])\n",
    "newRow.append(score.history['val_acc'][-1])\n",
    "newRow.append(score.history['val_mae'][-1])\n",
    "newRow.append(score.history['val_mse'][-1])\n",
    "newDF = pd.DataFrame([newRow],columns=['drop1','drop2','drop3']+['loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse']+['loss2', 'acc2', 'mae2', 'mse2', 'val_loss2', 'val_acc2', 'val_mae2', 'val_mse2']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c764834",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,newDF])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1fe7dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17938"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del(model)\n",
    "del(score)\n",
    "del(newRow)\n",
    "del(newDF)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad85cce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop1</th>\n",
       "      <th>drop2</th>\n",
       "      <th>drop3</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>loss2</th>\n",
       "      <th>acc2</th>\n",
       "      <th>mae2</th>\n",
       "      <th>mse2</th>\n",
       "      <th>val_loss2</th>\n",
       "      <th>val_acc2</th>\n",
       "      <th>val_mae2</th>\n",
       "      <th>val_mse2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.089701</td>\n",
       "      <td>0.973967</td>\n",
       "      <td>0.241858</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.110041</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.239948</td>\n",
       "      <td>0.14545</td>\n",
       "      <td>0.089701</td>\n",
       "      <td>0.973967</td>\n",
       "      <td>0.241858</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.110041</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.239948</td>\n",
       "      <td>0.14545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drop1  drop2  drop3      loss       acc       mae       mse  val_loss  \\\n",
       "0    0.0    0.0    0.0  0.089701  0.973967  0.241858  0.146191  0.110041   \n",
       "\n",
       "   val_acc   val_mae  val_mse     loss2      acc2      mae2      mse2  \\\n",
       "0   0.9663  0.239948  0.14545  0.089701  0.973967  0.241858  0.146191   \n",
       "\n",
       "   val_loss2  val_acc2  val_mae2  val_mse2  \n",
       "0   0.110041    0.9663  0.239948   0.14545  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bb72195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [9], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m opt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[0;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 23\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_trainM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trainM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_testM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_testM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m newRow \u001b[38;5;241m=\u001b[39m [i1,i2,i3]\n\u001b[0;32m     26\u001b[0m newRow\u001b[38;5;241m.\u001b[39mappend(score\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m50\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "for i1 in [0.0,0.25,0.5,0.75]:\n",
    "    for i2 in [0.0,0.25,0.5,0.75]:\n",
    "        for i3 in [0.0,0.25,0.5,0.75]:\n",
    "            if i1 != 0.0 or i2 != 0.0 or i3 != 0.0:\n",
    "                \n",
    "                model = Sequential()\n",
    "\n",
    "                model.add(Dense(300, activation='sigmoid', input_shape = (784,)))\n",
    "                if i1 != 0.0:\n",
    "                    model.add(Dropout(i1))\n",
    "                model.add(Dense(300, activation='sigmoid',))\n",
    "                if i2 != 0.0:\n",
    "                    model.add(Dropout(i2))\n",
    "                model.add(Dense(300, activation='sigmoid',))\n",
    "                if i3 != 0.0:\n",
    "                    model.add(Dropout(i3))\n",
    "                model.add(Dense(10, activation='sigmoid',))\n",
    "                \n",
    "                opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "                model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc','mae','mse'])\n",
    "\n",
    "                score = model.fit(x_trainM, y_trainM, epochs=75, batch_size=80 ,validation_data=(x_testM, y_testM),verbose=0)\n",
    "                \n",
    "                newRow = [i1,i2,i3]\n",
    "                newRow.append(score.history['loss'][50])\n",
    "                newRow.append(score.history['acc'][50])\n",
    "                newRow.append(score.history['mae'][50])\n",
    "                newRow.append(score.history['mse'][50])\n",
    "                newRow.append(score.history['val_loss'][50])\n",
    "                newRow.append(score.history['val_acc'][50])\n",
    "                newRow.append(score.history['val_mae'][50])\n",
    "                newRow.append(score.history['val_mse'][50])\n",
    "                newRow.append(score.history['loss'][-1])\n",
    "                newRow.append(score.history['acc'][-1])\n",
    "                newRow.append(score.history['mae'][-1])\n",
    "                newRow.append(score.history['mse'][-1])\n",
    "                newRow.append(score.history['val_loss'][-1])\n",
    "                newRow.append(score.history['val_acc'][-1])\n",
    "                newRow.append(score.history['val_mae'][-1])\n",
    "                newRow.append(score.history['val_mse'][-1])\n",
    "                newDF = pd.DataFrame([newRow],columns=['drop1','drop2','drop3']+['loss', 'acc', 'mae', 'mse', 'val_loss', 'val_acc', 'val_mae', 'val_mse']+['loss2', 'acc2', 'mae2', 'mse2', 'val_loss2', 'val_acc2', 'val_mae2', 'val_mse2']) \n",
    "                df = pd.concat([df,newDF])\n",
    "                \n",
    "                del(model)\n",
    "                del(score)\n",
    "                del(newRow)\n",
    "                del(newDF)\n",
    "                gc.collect()\n",
    "                \n",
    "                print(count)\n",
    "                count += 1\n",
    "print(\"FINISHED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "211c8d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>drop1</th>\n",
       "      <th>drop2</th>\n",
       "      <th>drop3</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_mae</th>\n",
       "      <th>val_mse</th>\n",
       "      <th>loss2</th>\n",
       "      <th>acc2</th>\n",
       "      <th>mae2</th>\n",
       "      <th>mse2</th>\n",
       "      <th>val_loss2</th>\n",
       "      <th>val_acc2</th>\n",
       "      <th>val_mae2</th>\n",
       "      <th>val_mse2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.089701</td>\n",
       "      <td>0.973967</td>\n",
       "      <td>0.241858</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.110041</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.239948</td>\n",
       "      <td>0.145450</td>\n",
       "      <td>0.089701</td>\n",
       "      <td>0.973967</td>\n",
       "      <td>0.241858</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.110041</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.239948</td>\n",
       "      <td>0.145450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.100131</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>0.228168</td>\n",
       "      <td>0.137026</td>\n",
       "      <td>0.111061</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.223350</td>\n",
       "      <td>0.131720</td>\n",
       "      <td>0.060317</td>\n",
       "      <td>0.982300</td>\n",
       "      <td>0.189308</td>\n",
       "      <td>0.112316</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.183967</td>\n",
       "      <td>0.106649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.114484</td>\n",
       "      <td>0.966350</td>\n",
       "      <td>0.223520</td>\n",
       "      <td>0.135632</td>\n",
       "      <td>0.118750</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.212945</td>\n",
       "      <td>0.124171</td>\n",
       "      <td>0.074655</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.186734</td>\n",
       "      <td>0.112178</td>\n",
       "      <td>0.093808</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>0.173692</td>\n",
       "      <td>0.097936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.959417</td>\n",
       "      <td>0.185931</td>\n",
       "      <td>0.110831</td>\n",
       "      <td>0.125485</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.162262</td>\n",
       "      <td>0.084686</td>\n",
       "      <td>0.093003</td>\n",
       "      <td>0.972833</td>\n",
       "      <td>0.155996</td>\n",
       "      <td>0.092825</td>\n",
       "      <td>0.099381</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.063480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.110049</td>\n",
       "      <td>0.966817</td>\n",
       "      <td>0.229286</td>\n",
       "      <td>0.136357</td>\n",
       "      <td>0.116207</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.225400</td>\n",
       "      <td>0.131769</td>\n",
       "      <td>0.073517</td>\n",
       "      <td>0.977550</td>\n",
       "      <td>0.200227</td>\n",
       "      <td>0.119043</td>\n",
       "      <td>0.088448</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>0.195495</td>\n",
       "      <td>0.113864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.118907</td>\n",
       "      <td>0.965250</td>\n",
       "      <td>0.255382</td>\n",
       "      <td>0.157491</td>\n",
       "      <td>0.118708</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.248532</td>\n",
       "      <td>0.149016</td>\n",
       "      <td>0.080318</td>\n",
       "      <td>0.975517</td>\n",
       "      <td>0.220908</td>\n",
       "      <td>0.133955</td>\n",
       "      <td>0.094132</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.213991</td>\n",
       "      <td>0.125267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.131760</td>\n",
       "      <td>0.961200</td>\n",
       "      <td>0.226428</td>\n",
       "      <td>0.135517</td>\n",
       "      <td>0.124021</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.215585</td>\n",
       "      <td>0.121496</td>\n",
       "      <td>0.089023</td>\n",
       "      <td>0.973133</td>\n",
       "      <td>0.195158</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.096629</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>0.182121</td>\n",
       "      <td>0.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.162737</td>\n",
       "      <td>0.953400</td>\n",
       "      <td>0.228109</td>\n",
       "      <td>0.144087</td>\n",
       "      <td>0.138157</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.205434</td>\n",
       "      <td>0.116490</td>\n",
       "      <td>0.113531</td>\n",
       "      <td>0.967867</td>\n",
       "      <td>0.196505</td>\n",
       "      <td>0.123115</td>\n",
       "      <td>0.107265</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.169409</td>\n",
       "      <td>0.091739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.130267</td>\n",
       "      <td>0.961150</td>\n",
       "      <td>0.243109</td>\n",
       "      <td>0.149118</td>\n",
       "      <td>0.125187</td>\n",
       "      <td>0.9609</td>\n",
       "      <td>0.237556</td>\n",
       "      <td>0.142075</td>\n",
       "      <td>0.090461</td>\n",
       "      <td>0.972900</td>\n",
       "      <td>0.219397</td>\n",
       "      <td>0.134100</td>\n",
       "      <td>0.096757</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.214520</td>\n",
       "      <td>0.127635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   drop1  drop2  drop3      loss       acc       mae       mse  val_loss  \\\n",
       "0    0.0   0.00   0.00  0.089701  0.973967  0.241858  0.146191  0.110041   \n",
       "0    0.0   0.00   0.25  0.100131  0.971000  0.228168  0.137026  0.111061   \n",
       "0    0.0   0.00   0.50  0.114484  0.966350  0.223520  0.135632  0.118750   \n",
       "0    0.0   0.00   0.75  0.142056  0.959417  0.185931  0.110831  0.125485   \n",
       "0    0.0   0.25   0.00  0.110049  0.966817  0.229286  0.136357  0.116207   \n",
       "0    0.0   0.25   0.25  0.118907  0.965250  0.255382  0.157491  0.118708   \n",
       "0    0.0   0.25   0.50  0.131760  0.961200  0.226428  0.135517  0.124021   \n",
       "0    0.0   0.25   0.75  0.162737  0.953400  0.228109  0.144087  0.138157   \n",
       "0    0.0   0.50   0.00  0.130267  0.961150  0.243109  0.149118  0.125187   \n",
       "\n",
       "   val_acc   val_mae   val_mse     loss2      acc2      mae2      mse2  \\\n",
       "0   0.9663  0.239948  0.145450  0.089701  0.973967  0.241858  0.146191   \n",
       "0   0.9649  0.223350  0.131720  0.060317  0.982300  0.189308  0.112316   \n",
       "0   0.9639  0.212945  0.124171  0.074655  0.977600  0.186734  0.112178   \n",
       "0   0.9609  0.162262  0.084686  0.093003  0.972833  0.155996  0.092825   \n",
       "0   0.9644  0.225400  0.131769  0.073517  0.977550  0.200227  0.119043   \n",
       "0   0.9634  0.248532  0.149016  0.080318  0.975517  0.220908  0.133955   \n",
       "0   0.9605  0.215585  0.121496  0.089023  0.973133  0.195158  0.115311   \n",
       "0   0.9581  0.205434  0.116490  0.113531  0.967867  0.196505  0.123115   \n",
       "0   0.9609  0.237556  0.142075  0.090461  0.972900  0.219397  0.134100   \n",
       "\n",
       "   val_loss2  val_acc2  val_mae2  val_mse2  \n",
       "0   0.110041    0.9663  0.239948  0.145450  \n",
       "0   0.087719    0.9725  0.183967  0.106649  \n",
       "0   0.093808    0.9710  0.173692  0.097936  \n",
       "0   0.099381    0.9694  0.127907  0.063480  \n",
       "0   0.088448    0.9722  0.195495  0.113864  \n",
       "0   0.094132    0.9706  0.213991  0.125267  \n",
       "0   0.096629    0.9705  0.182121  0.099609  \n",
       "0   0.107265    0.9688  0.169409  0.091739  \n",
       "0   0.096757    0.9699  0.214520  0.127635  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e373013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Results-MNIST.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b155cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
