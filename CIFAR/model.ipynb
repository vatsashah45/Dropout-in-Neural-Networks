{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0287faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Dense, Dropout\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd56d7",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9dd02da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_trainC = np.loadtxt('x_trainC')\n",
    "y_trainC = np.loadtxt('y_trainC')\n",
    "x_testC = np.loadtxt('x_testC')\n",
    "y_testC = np.loadtxt('y_testC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f6965c",
   "metadata": {},
   "source": [
    "## Working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe923021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 518)               530950    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 518)               268842    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 518)               268842    \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 518)               268842    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 518)               268842    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                5190      \n",
      "=================================================================\n",
      "Total params: 1,611,508\n",
      "Trainable params: 1,611,508\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2500/2500 [==============================] - 7s 2ms/step - loss: 2.3123 - acc: 0.1000 - val_loss: 2.3098 - val_acc: 0.1000\n",
      "Epoch 2/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3101 - acc: 0.0969 - val_loss: 2.3049 - val_acc: 0.1000\n",
      "Epoch 3/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3082 - acc: 0.1005 - val_loss: 2.3060 - val_acc: 0.1000\n",
      "Epoch 4/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3073 - acc: 0.1000 - val_loss: 2.3054 - val_acc: 0.1000\n",
      "Epoch 5/100\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 2.3064 - acc: 0.1004 - val_loss: 2.3053 - val_acc: 0.1000\n",
      "Epoch 6/100\n",
      "2500/2500 [==============================] - 6s 2ms/step - loss: 2.3062 - acc: 0.0992 - val_loss: 2.3051 - val_acc: 0.1000\n",
      "Epoch 7/100\n",
      "1225/2500 [=============>................] - ETA: 2s - loss: 2.3058 - acc: 0.0949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m opt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-5\u001b[39m)\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 17\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_trainC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_trainC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_testC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_testC\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m json\u001b[38;5;241m.\u001b[39mdump(score\u001b[38;5;241m.\u001b[39mhistory, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorkingModel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(518, activation='sigmoid', input_shape = (1024,)))\n",
    "model.add(Dense(518, activation='sigmoid'))\n",
    "model.add(Dense(518, activation='sigmoid'))\n",
    "model.add(Dense(518, activation='sigmoid'))\n",
    "model.add(Dense(518, activation='sigmoid'))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='sigmoid',))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "score = model.fit(x_trainC, y_trainC, epochs=100, batch_size=20 ,validation_data=(x_testC, y_testC))\n",
    "json.dump(score.history, open(\"WorkingModel\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53044ffd",
   "metadata": {},
   "source": [
    "## Overfitted model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a3545d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 2048)              1605632   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1024)              2097152   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 2048)              2097152   \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 5,820,426\n",
      "Trainable params: 5,820,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 2s 8ms/step - loss: 2.2961 - acc: 0.1223 - val_loss: 2.2238 - val_acc: 0.1180\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 2.1196 - acc: 0.3040 - val_loss: 1.9690 - val_acc: 0.3371\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 1.6629 - acc: 0.5093 - val_loss: 1.3787 - val_acc: 0.6131\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 1.1724 - acc: 0.6647 - val_loss: 1.0410 - val_acc: 0.7136\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.9073 - acc: 0.7267 - val_loss: 0.8467 - val_acc: 0.7639\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.7491 - acc: 0.7853 - val_loss: 0.7457 - val_acc: 0.7497\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.6419 - acc: 0.8217 - val_loss: 0.6481 - val_acc: 0.8011\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5621 - acc: 0.8443 - val_loss: 0.5849 - val_acc: 0.8254\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.5056 - acc: 0.8527 - val_loss: 0.5272 - val_acc: 0.8454\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.4607 - acc: 0.8670 - val_loss: 0.4930 - val_acc: 0.8544\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4316 - acc: 0.8757 - val_loss: 0.4768 - val_acc: 0.8514\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.4021 - acc: 0.8823 - val_loss: 0.4648 - val_acc: 0.8549\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3815 - acc: 0.8897 - val_loss: 0.4377 - val_acc: 0.8667\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3600 - acc: 0.8947 - val_loss: 0.4321 - val_acc: 0.8701\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3416 - acc: 0.9013 - val_loss: 0.4087 - val_acc: 0.8762\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3309 - acc: 0.8993 - val_loss: 0.4032 - val_acc: 0.8788\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3181 - acc: 0.9070 - val_loss: 0.3966 - val_acc: 0.8787\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3012 - acc: 0.9143 - val_loss: 0.3977 - val_acc: 0.8794\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2937 - acc: 0.9127 - val_loss: 0.3817 - val_acc: 0.8852\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2884 - acc: 0.9130 - val_loss: 0.3767 - val_acc: 0.8879\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2836 - acc: 0.9160 - val_loss: 0.3734 - val_acc: 0.8882\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2710 - acc: 0.9213 - val_loss: 0.3721 - val_acc: 0.8902\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2643 - acc: 0.9227 - val_loss: 0.3706 - val_acc: 0.8880\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2602 - acc: 0.9270 - val_loss: 0.3829 - val_acc: 0.8830\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2514 - acc: 0.9253 - val_loss: 0.3716 - val_acc: 0.8892\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2461 - acc: 0.9257 - val_loss: 0.3548 - val_acc: 0.8955\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2389 - acc: 0.9253 - val_loss: 0.3632 - val_acc: 0.8923\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2357 - acc: 0.9320 - val_loss: 0.3642 - val_acc: 0.8897\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2317 - acc: 0.9323 - val_loss: 0.3573 - val_acc: 0.8957\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2223 - acc: 0.9317 - val_loss: 0.3629 - val_acc: 0.8912\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2199 - acc: 0.9377 - val_loss: 0.3503 - val_acc: 0.8965\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2106 - acc: 0.9400 - val_loss: 0.3579 - val_acc: 0.8954\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2077 - acc: 0.9407 - val_loss: 0.3794 - val_acc: 0.8886\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2033 - acc: 0.9440 - val_loss: 0.3850 - val_acc: 0.8861\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1987 - acc: 0.9403 - val_loss: 0.3584 - val_acc: 0.8970\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1982 - acc: 0.9410 - val_loss: 0.3520 - val_acc: 0.8975\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1935 - acc: 0.9430 - val_loss: 0.3633 - val_acc: 0.8948\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1868 - acc: 0.9423 - val_loss: 0.3561 - val_acc: 0.8987\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1873 - acc: 0.9430 - val_loss: 0.3636 - val_acc: 0.8935\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1814 - acc: 0.9470 - val_loss: 0.3524 - val_acc: 0.8978\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1792 - acc: 0.9523 - val_loss: 0.3508 - val_acc: 0.8992\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1730 - acc: 0.9493 - val_loss: 0.3444 - val_acc: 0.9020\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1683 - acc: 0.9517 - val_loss: 0.3521 - val_acc: 0.8989\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1660 - acc: 0.9513 - val_loss: 0.3693 - val_acc: 0.8953\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1607 - acc: 0.9517 - val_loss: 0.3563 - val_acc: 0.8980\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1562 - acc: 0.9547 - val_loss: 0.3546 - val_acc: 0.9014\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1526 - acc: 0.9580 - val_loss: 0.3571 - val_acc: 0.9001\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1503 - acc: 0.9523 - val_loss: 0.3555 - val_acc: 0.8996\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1493 - acc: 0.9573 - val_loss: 0.3619 - val_acc: 0.8983\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1448 - acc: 0.9563 - val_loss: 0.3656 - val_acc: 0.8989\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1412 - acc: 0.9587 - val_loss: 0.3588 - val_acc: 0.9026\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1410 - acc: 0.9600 - val_loss: 0.3612 - val_acc: 0.9006\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1408 - acc: 0.9607 - val_loss: 0.3607 - val_acc: 0.8991\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1313 - acc: 0.9640 - val_loss: 0.4059 - val_acc: 0.8876\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.1345 - acc: 0.9597 - val_loss: 0.3543 - val_acc: 0.9051\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1282 - acc: 0.9643 - val_loss: 0.3736 - val_acc: 0.8975\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1235 - acc: 0.9647 - val_loss: 0.3580 - val_acc: 0.9026\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1210 - acc: 0.9663 - val_loss: 0.3595 - val_acc: 0.9024\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1178 - acc: 0.9677 - val_loss: 0.3701 - val_acc: 0.9003\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1161 - acc: 0.9667 - val_loss: 0.3743 - val_acc: 0.8998\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1125 - acc: 0.9690 - val_loss: 0.3719 - val_acc: 0.9003\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1109 - acc: 0.9717 - val_loss: 0.3612 - val_acc: 0.9043\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1064 - acc: 0.9683 - val_loss: 0.3864 - val_acc: 0.8973\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1072 - acc: 0.9713 - val_loss: 0.3750 - val_acc: 0.9017\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.1052 - acc: 0.9730 - val_loss: 0.3743 - val_acc: 0.9019\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0985 - acc: 0.9740 - val_loss: 0.3749 - val_acc: 0.9027\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0984 - acc: 0.9750 - val_loss: 0.3788 - val_acc: 0.9031\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0936 - acc: 0.9753 - val_loss: 0.3805 - val_acc: 0.9024\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0905 - acc: 0.9780 - val_loss: 0.3851 - val_acc: 0.9013\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0907 - acc: 0.9763 - val_loss: 0.3914 - val_acc: 0.9019\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0878 - acc: 0.9777 - val_loss: 0.4171 - val_acc: 0.8933\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0879 - acc: 0.9783 - val_loss: 0.3979 - val_acc: 0.8995\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0805 - acc: 0.9800 - val_loss: 0.4053 - val_acc: 0.8994\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0799 - acc: 0.9820 - val_loss: 0.3958 - val_acc: 0.8999\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0827 - acc: 0.9797 - val_loss: 0.4047 - val_acc: 0.8992\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0784 - acc: 0.9810 - val_loss: 0.3940 - val_acc: 0.9023\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0745 - acc: 0.9833 - val_loss: 0.4060 - val_acc: 0.8987\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0750 - acc: 0.9790 - val_loss: 0.3954 - val_acc: 0.9026\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0762 - acc: 0.9803 - val_loss: 0.4198 - val_acc: 0.8971\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0672 - acc: 0.9843 - val_loss: 0.4025 - val_acc: 0.9016\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0643 - acc: 0.9860 - val_loss: 0.4223 - val_acc: 0.8985\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0648 - acc: 0.9850 - val_loss: 0.4143 - val_acc: 0.9016\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0628 - acc: 0.9863 - val_loss: 0.4163 - val_acc: 0.9009\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0625 - acc: 0.9863 - val_loss: 0.4200 - val_acc: 0.8986\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0598 - acc: 0.9863 - val_loss: 0.4264 - val_acc: 0.8969\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0583 - acc: 0.9873 - val_loss: 0.4251 - val_acc: 0.9009\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0559 - acc: 0.9880 - val_loss: 0.4240 - val_acc: 0.9007\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0573 - acc: 0.9857 - val_loss: 0.4420 - val_acc: 0.8977\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0564 - acc: 0.9853 - val_loss: 0.4419 - val_acc: 0.8976\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0507 - acc: 0.9897 - val_loss: 0.4394 - val_acc: 0.8993\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0495 - acc: 0.9890 - val_loss: 0.4418 - val_acc: 0.8983\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.0455 - acc: 0.9913 - val_loss: 0.4380 - val_acc: 0.9003\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0436 - acc: 0.9930 - val_loss: 0.4625 - val_acc: 0.8959\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0439 - acc: 0.9910 - val_loss: 0.4555 - val_acc: 0.8959\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0443 - acc: 0.9917 - val_loss: 0.4708 - val_acc: 0.8950\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0426 - acc: 0.9917 - val_loss: 0.4564 - val_acc: 0.8980\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0409 - acc: 0.9923 - val_loss: 0.4621 - val_acc: 0.8976\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0385 - acc: 0.9917 - val_loss: 0.4551 - val_acc: 0.9011\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0368 - acc: 0.9923 - val_loss: 0.4598 - val_acc: 0.8989\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.0344 - acc: 0.9940 - val_loss: 0.4650 - val_acc: 0.8988\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(2048, activation='sigmoid', input_shape = (784,),use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "model.add(Dense(1024, activation='sigmoid',use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "model.add(Dense(2048, activation='sigmoid',use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "#model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "score = model.fit(x_trainM[:3000], y_trainM[:3000], batch_size= 20, epochs=100 ,validation_data=(x_testM, y_testM))\n",
    "json.dump(score.history, open(\"OverfittedModel\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fb65a0",
   "metadata": {},
   "source": [
    "## Model using Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "885642fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 2048)              1605632   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1024)              2097152   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 2048)              2097152   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 5,820,426\n",
      "Trainable params: 5,820,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "150/150 [==============================] - 2s 8ms/step - loss: 2.6241 - acc: 0.0990 - val_loss: 2.2931 - val_acc: 0.2363\n",
      "Epoch 2/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.5622 - acc: 0.1103 - val_loss: 2.2726 - val_acc: 0.1499\n",
      "Epoch 3/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.4933 - acc: 0.1213 - val_loss: 2.2278 - val_acc: 0.1760\n",
      "Epoch 4/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.4518 - acc: 0.1233 - val_loss: 2.1684 - val_acc: 0.3164\n",
      "Epoch 5/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.3272 - acc: 0.1507 - val_loss: 2.0817 - val_acc: 0.4496\n",
      "Epoch 6/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 2.1880 - acc: 0.2130 - val_loss: 1.9093 - val_acc: 0.5345\n",
      "Epoch 7/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 2.0091 - acc: 0.2900 - val_loss: 1.6768 - val_acc: 0.5235\n",
      "Epoch 8/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.7644 - acc: 0.3913 - val_loss: 1.4378 - val_acc: 0.5657\n",
      "Epoch 9/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.5012 - acc: 0.4803 - val_loss: 1.2226 - val_acc: 0.6281\n",
      "Epoch 10/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.3305 - acc: 0.5423 - val_loss: 1.0742 - val_acc: 0.6782\n",
      "Epoch 11/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.1760 - acc: 0.5977 - val_loss: 0.9594 - val_acc: 0.7029\n",
      "Epoch 12/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 1.0743 - acc: 0.6257 - val_loss: 0.8794 - val_acc: 0.7113\n",
      "Epoch 13/100\n",
      "150/150 [==============================] - 1s 9ms/step - loss: 0.9982 - acc: 0.6527 - val_loss: 0.8088 - val_acc: 0.7527\n",
      "Epoch 14/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.9162 - acc: 0.6833 - val_loss: 0.7746 - val_acc: 0.7558\n",
      "Epoch 15/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.8452 - acc: 0.7053 - val_loss: 0.7192 - val_acc: 0.7875\n",
      "Epoch 16/100\n",
      "150/150 [==============================] - 1s 8ms/step - loss: 0.8225 - acc: 0.7223 - val_loss: 0.6798 - val_acc: 0.7912\n",
      "Epoch 17/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.7830 - acc: 0.7263 - val_loss: 0.6381 - val_acc: 0.8080\n",
      "Epoch 18/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.7187 - acc: 0.7650 - val_loss: 0.6201 - val_acc: 0.8042\n",
      "Epoch 19/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6949 - acc: 0.7753 - val_loss: 0.5986 - val_acc: 0.8101\n",
      "Epoch 20/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6544 - acc: 0.7947 - val_loss: 0.5673 - val_acc: 0.8199\n",
      "Epoch 21/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6247 - acc: 0.7953 - val_loss: 0.5438 - val_acc: 0.8298\n",
      "Epoch 22/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.6074 - acc: 0.8003 - val_loss: 0.5205 - val_acc: 0.8355\n",
      "Epoch 23/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5756 - acc: 0.8143 - val_loss: 0.5122 - val_acc: 0.8411\n",
      "Epoch 24/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5706 - acc: 0.8290 - val_loss: 0.4969 - val_acc: 0.8450\n",
      "Epoch 25/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5522 - acc: 0.8183 - val_loss: 0.4801 - val_acc: 0.8479\n",
      "Epoch 26/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5422 - acc: 0.8227 - val_loss: 0.4767 - val_acc: 0.8489\n",
      "Epoch 27/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5082 - acc: 0.8413 - val_loss: 0.4716 - val_acc: 0.8524\n",
      "Epoch 28/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5018 - acc: 0.8377 - val_loss: 0.4523 - val_acc: 0.8582\n",
      "Epoch 29/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.5043 - acc: 0.8437 - val_loss: 0.4474 - val_acc: 0.8614\n",
      "Epoch 30/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4843 - acc: 0.8423 - val_loss: 0.4391 - val_acc: 0.8641\n",
      "Epoch 31/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4740 - acc: 0.8493 - val_loss: 0.4332 - val_acc: 0.8651\n",
      "Epoch 32/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4641 - acc: 0.8490 - val_loss: 0.4260 - val_acc: 0.8699\n",
      "Epoch 33/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4548 - acc: 0.8563 - val_loss: 0.4197 - val_acc: 0.8695\n",
      "Epoch 34/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4496 - acc: 0.8560 - val_loss: 0.4133 - val_acc: 0.8745\n",
      "Epoch 35/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4178 - acc: 0.8727 - val_loss: 0.4097 - val_acc: 0.8742\n",
      "Epoch 36/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4150 - acc: 0.8643 - val_loss: 0.4037 - val_acc: 0.8770\n",
      "Epoch 37/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4274 - acc: 0.8633 - val_loss: 0.4069 - val_acc: 0.8749\n",
      "Epoch 38/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4085 - acc: 0.8700 - val_loss: 0.3972 - val_acc: 0.8793\n",
      "Epoch 39/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4019 - acc: 0.8690 - val_loss: 0.3927 - val_acc: 0.8793\n",
      "Epoch 40/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.4043 - acc: 0.8740 - val_loss: 0.3906 - val_acc: 0.8826\n",
      "Epoch 41/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3950 - acc: 0.8723 - val_loss: 0.3916 - val_acc: 0.8794\n",
      "Epoch 42/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3837 - acc: 0.8743 - val_loss: 0.3889 - val_acc: 0.8820\n",
      "Epoch 43/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3800 - acc: 0.8770 - val_loss: 0.3828 - val_acc: 0.8830\n",
      "Epoch 44/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3918 - acc: 0.8840 - val_loss: 0.3848 - val_acc: 0.8813\n",
      "Epoch 45/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3686 - acc: 0.8880 - val_loss: 0.3849 - val_acc: 0.8812\n",
      "Epoch 46/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3707 - acc: 0.8827 - val_loss: 0.3781 - val_acc: 0.8851\n",
      "Epoch 47/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3734 - acc: 0.8880 - val_loss: 0.3860 - val_acc: 0.8812\n",
      "Epoch 48/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3672 - acc: 0.8807 - val_loss: 0.3952 - val_acc: 0.8772\n",
      "Epoch 49/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3492 - acc: 0.8860 - val_loss: 0.3716 - val_acc: 0.8869\n",
      "Epoch 50/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3612 - acc: 0.8800 - val_loss: 0.3694 - val_acc: 0.8894\n",
      "Epoch 51/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3439 - acc: 0.8983 - val_loss: 0.3667 - val_acc: 0.8886\n",
      "Epoch 52/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.3328 - acc: 0.8970 - val_loss: 0.3784 - val_acc: 0.8846\n",
      "Epoch 53/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3288 - acc: 0.8983 - val_loss: 0.3697 - val_acc: 0.8870\n",
      "Epoch 54/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3385 - acc: 0.8920 - val_loss: 0.3681 - val_acc: 0.8887\n",
      "Epoch 55/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3367 - acc: 0.8950 - val_loss: 0.3623 - val_acc: 0.8919\n",
      "Epoch 56/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3293 - acc: 0.8927 - val_loss: 0.3644 - val_acc: 0.8899\n",
      "Epoch 57/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3328 - acc: 0.9017 - val_loss: 0.3590 - val_acc: 0.8928\n",
      "Epoch 58/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3208 - acc: 0.9030 - val_loss: 0.3602 - val_acc: 0.8926\n",
      "Epoch 59/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3074 - acc: 0.9087 - val_loss: 0.3612 - val_acc: 0.8929\n",
      "Epoch 60/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3100 - acc: 0.9020 - val_loss: 0.3643 - val_acc: 0.8920\n",
      "Epoch 61/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3298 - acc: 0.8913 - val_loss: 0.3645 - val_acc: 0.8904\n",
      "Epoch 62/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3043 - acc: 0.9080 - val_loss: 0.3609 - val_acc: 0.8917\n",
      "Epoch 63/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3024 - acc: 0.9057 - val_loss: 0.3540 - val_acc: 0.8942\n",
      "Epoch 64/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3014 - acc: 0.9100 - val_loss: 0.3593 - val_acc: 0.8913\n",
      "Epoch 65/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2947 - acc: 0.9117 - val_loss: 0.3579 - val_acc: 0.8936\n",
      "Epoch 66/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2953 - acc: 0.9053 - val_loss: 0.3539 - val_acc: 0.8948\n",
      "Epoch 67/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2927 - acc: 0.9080 - val_loss: 0.3524 - val_acc: 0.8951\n",
      "Epoch 68/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.3066 - acc: 0.9023 - val_loss: 0.3488 - val_acc: 0.8965\n",
      "Epoch 69/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2952 - acc: 0.9050 - val_loss: 0.3501 - val_acc: 0.8964\n",
      "Epoch 70/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2861 - acc: 0.9083 - val_loss: 0.3500 - val_acc: 0.8953\n",
      "Epoch 71/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2885 - acc: 0.9100 - val_loss: 0.3576 - val_acc: 0.8933\n",
      "Epoch 72/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2719 - acc: 0.9193 - val_loss: 0.3481 - val_acc: 0.8974\n",
      "Epoch 73/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2852 - acc: 0.9103 - val_loss: 0.3469 - val_acc: 0.8968\n",
      "Epoch 74/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2734 - acc: 0.9123 - val_loss: 0.3476 - val_acc: 0.8970\n",
      "Epoch 75/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2754 - acc: 0.9123 - val_loss: 0.3512 - val_acc: 0.8964\n",
      "Epoch 76/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2747 - acc: 0.9087 - val_loss: 0.3397 - val_acc: 0.9018\n",
      "Epoch 77/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2701 - acc: 0.9200 - val_loss: 0.3414 - val_acc: 0.9023\n",
      "Epoch 78/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2712 - acc: 0.9103 - val_loss: 0.3461 - val_acc: 0.8983\n",
      "Epoch 79/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2526 - acc: 0.9220 - val_loss: 0.3430 - val_acc: 0.9000\n",
      "Epoch 80/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2722 - acc: 0.9170 - val_loss: 0.3455 - val_acc: 0.8986\n",
      "Epoch 81/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2596 - acc: 0.9193 - val_loss: 0.3400 - val_acc: 0.9015\n",
      "Epoch 82/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2611 - acc: 0.9177 - val_loss: 0.3397 - val_acc: 0.9006\n",
      "Epoch 83/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2652 - acc: 0.9140 - val_loss: 0.3386 - val_acc: 0.9015\n",
      "Epoch 84/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2566 - acc: 0.9170 - val_loss: 0.3384 - val_acc: 0.9025\n",
      "Epoch 85/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2506 - acc: 0.9227 - val_loss: 0.3378 - val_acc: 0.9009\n",
      "Epoch 86/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2407 - acc: 0.9253 - val_loss: 0.3363 - val_acc: 0.9017\n",
      "Epoch 87/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2495 - acc: 0.9197 - val_loss: 0.3378 - val_acc: 0.9011\n",
      "Epoch 88/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2589 - acc: 0.9177 - val_loss: 0.3409 - val_acc: 0.8989\n",
      "Epoch 89/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2345 - acc: 0.9287 - val_loss: 0.3333 - val_acc: 0.9028\n",
      "Epoch 90/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2442 - acc: 0.9187 - val_loss: 0.3382 - val_acc: 0.9021\n",
      "Epoch 91/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2369 - acc: 0.9243 - val_loss: 0.3346 - val_acc: 0.9039\n",
      "Epoch 92/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2437 - acc: 0.9227 - val_loss: 0.3375 - val_acc: 0.9028\n",
      "Epoch 93/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2312 - acc: 0.9250 - val_loss: 0.3333 - val_acc: 0.9054\n",
      "Epoch 94/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2265 - acc: 0.9280 - val_loss: 0.3342 - val_acc: 0.9038\n",
      "Epoch 95/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2129 - acc: 0.9333 - val_loss: 0.3314 - val_acc: 0.9053\n",
      "Epoch 96/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2329 - acc: 0.9280 - val_loss: 0.3425 - val_acc: 0.9003\n",
      "Epoch 97/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2206 - acc: 0.9333 - val_loss: 0.3326 - val_acc: 0.9049\n",
      "Epoch 98/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2300 - acc: 0.9257 - val_loss: 0.3346 - val_acc: 0.9042\n",
      "Epoch 99/100\n",
      "150/150 [==============================] - 1s 7ms/step - loss: 0.2229 - acc: 0.9280 - val_loss: 0.3285 - val_acc: 0.9061\n",
      "Epoch 100/100\n",
      "150/150 [==============================] - 1s 6ms/step - loss: 0.2269 - acc: 0.9303 - val_loss: 0.3346 - val_acc: 0.9043\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(2048, activation='sigmoid', input_shape = (784,),use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(1024, activation='sigmoid',use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2048, activation='sigmoid',use_bias=False,kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "score = model.fit(x_trainM[:3000], y_trainM[:3000], batch_size= 20, epochs=100 ,validation_data=(x_testM, y_testM))\n",
    "json.dump(score.history, open(\"DropoutModel\", 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d036bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GPU name: ', tf.config.experimental.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ef38b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
